WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:03.524
你已经知道 ORB 算法的原理

00:00:03.524 --> 00:00:07.515
你可能会疑问 到底可以如何使用 ORB 描述符进行对象识别呢？

00:00:07.514 --> 00:00:10.830
我们来看一个示例 了解 ORB 可以如何检测到

00:00:10.830 --> 00:00:14.310
具有不同大小和方向的同一对象

00:00:14.310 --> 00:00:18.329
假设我想在其他图像中检测到此人的面孔

00:00:18.329 --> 00:00:20.729
例如在这个多人合影中

00:00:20.730 --> 00:00:23.594
我们将第一张图像称为训练图像

00:00:23.594 --> 00:00:26.070
第二张图像 即要对其进行人脸检测的图像

00:00:26.070 --> 00:00:28.890
称为查询图像

00:00:28.890 --> 00:00:30.929
给定这个训练图像

00:00:30.929 --> 00:00:34.079
我想在这个查询图像中查找相似的特征

00:00:34.079 --> 00:00:35.909
第一步是计算训练图像的 ORB 描述符

00:00:35.909 --> 00:00:39.149
并将其存储到内存中

00:00:39.149 --> 00:00:42.060
ORB 描述符将包含二元特征向量

00:00:42.060 --> 00:00:45.045
用于描述这个训练图像中的关键点

00:00:45.045 --> 00:00:49.725
第二步是计算并保存查询图像的 ORB 描述符

00:00:49.725 --> 00:00:53.939
获得训练和查询图像的描述符后

00:00:53.939 --> 00:00:56.549
最后一步是使用相应的描述符

00:00:56.549 --> 00:01:00.074
对这两个图像进行关键点匹配

00:01:00.075 --> 00:01:03.420
通常使用匹配函数来完成这一步

00:01:03.420 --> 00:01:06.900
匹配函数的目的是匹配两个不同图像的关键点

00:01:06.900 --> 00:01:08.880
方法是比较这两个图像的描述符

00:01:08.879 --> 00:01:11.295
看看它们是否很相近 可以匹配

00:01:11.295 --> 00:01:14.310
当匹配函数对比两个关键点时

00:01:14.310 --> 00:01:17.355
它会根据某种指标得出匹配质量

00:01:17.355 --> 00:01:21.280
这种指标表示关键点特征向量的相似性

00:01:21.280 --> 00:01:23.670
可以将这个指标看作

00:01:23.670 --> 00:01:26.790
与两个关键点之间的标准欧几里得距离相似

00:01:26.790 --> 00:01:28.440
某些指标会直接检测

00:01:28.439 --> 00:01:32.609
特征向量是否包含相似顺序的 1 和 0

00:01:32.609 --> 00:01:35.519
请注意 不同的匹配函数

00:01:35.519 --> 00:01:38.700
使用不同的指标来判断匹配质量

00:01:38.700 --> 00:01:42.030
对于 ORB 等使用的二元描述符来说

00:01:42.030 --> 00:01:46.454
通常使用汉明指标 因为它执行起来非常快

00:01:46.454 --> 00:01:50.250
汉明指标通过计算二元描述符之间的不同位数量

00:01:50.250 --> 00:01:54.388
判断两个关键点之间的匹配质量

00:01:54.388 --> 00:01:58.829
在比较训练图像和查询图像的关键点时

00:01:58.829 --> 00:02:02.954
差异数最少的关键点对被视为最佳匹配

00:02:02.954 --> 00:02:05.745
匹配函数对比完训练图像

00:02:05.745 --> 00:02:09.000
和查询图像中的所有关键点后

00:02:09.000 --> 00:02:11.745
返回最匹配的关键点对

00:02:11.745 --> 00:02:13.530
我们的训练图像和查询图像

00:02:13.530 --> 00:02:16.620
之间的最匹配点显示在此处

00:02:16.620 --> 00:02:20.480
可以清晰地看出训练图像和查询图像之间最匹配的点

00:02:20.479 --> 00:02:24.629
主要对应的是训练图像的面孔

00:02:24.629 --> 00:02:27.900
有一两个特征不是太匹配

00:02:27.900 --> 00:02:29.400
但是选择的原因可能是

00:02:29.400 --> 00:02:32.580
该图像区域的强度模式比较相似

00:02:32.580 --> 00:02:35.800
因为大部分点对应的是训练图像中的脸部

00:02:35.800 --> 00:02:38.340
可以看出匹配函数能够

00:02:38.340 --> 00:02:41.599
在查询图像中正确地识别该面孔

