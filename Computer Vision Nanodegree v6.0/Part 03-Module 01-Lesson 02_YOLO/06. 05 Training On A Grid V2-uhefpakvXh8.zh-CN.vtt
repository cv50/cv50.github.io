WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:04.419
在网格单元上训练需要一种非常特殊的训练数据

00:00:04.419 --> 00:00:07.080
要训练网络为每个单元格输出

00:00:07.080 --> 00:00:10.080
预测的类别得分和边界框向量

00:00:10.080 --> 00:00:12.544
我们需要一个用于比较的正确标注

00:00:12.544 --> 00:00:14.250
对于每个训练图像

00:00:14.250 --> 00:00:16.109
我们需要将其划分为网格

00:00:16.109 --> 00:00:19.949
并手动为每个网格单元分配一个正确标注

00:00:19.949 --> 00:00:22.660
获得这些带网格单元标记的训练数据后

00:00:22.660 --> 00:00:26.855
第二步是设计一个可以使用这些向量进行训练的 CNN

00:00:26.855 --> 00:00:30.230
因为我们的示例中是 7x10 网格

00:00:30.230 --> 00:00:34.259
每个网格单元具有相关的 8 维正确标注

00:00:34.259 --> 00:00:37.739
因此我们的 CNN 输出层大小

00:00:37.740 --> 00:00:42.025
应该为 7x10x8

00:00:42.024 --> 00:00:44.614
可以将其看做 7x10 图像

00:00:44.615 --> 00:00:46.170
深度为 8

00:00:46.170 --> 00:00:51.375
每个像素值是一个 8 维输出向量

00:00:51.375 --> 00:00:53.725
而不是像 RGB 图像那样是长度为 3 的向量

00:00:53.725 --> 00:00:56.189
这样的话 对于每个输入网格单元

00:00:56.189 --> 00:01:00.500
在 CNN 的输出层中都有一个 8 维输出向量

00:01:00.500 --> 00:01:03.659
例如 当网络看到第一个网格单元时

00:01:03.659 --> 00:01:07.829
它将在输出层左上角生成一个输出向量

00:01:07.829 --> 00:01:09.989
定义好这个输出形状后

00:01:09.989 --> 00:01:15.224
我们可以使用图像和真实网格向量作为输入训练 CNN

00:01:15.224 --> 00:01:17.280
训练 CNN 后

00:01:17.280 --> 00:01:21.045
我们可以使用它检测并定位测试图像中的对象

00:01:21.045 --> 00:01:25.200
接下来 我们将了解此方法如何生成准确的边界框

