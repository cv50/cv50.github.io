WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:05.165
我们来看看 YOLO 如何接受输入图像并检测多个对象

00:00:05.165 --> 00:00:08.879
假设有个 CNN 被训练成识别多个类别

00:00:08.880 --> 00:00:10.214
包括交通信号灯

00:00:10.214 --> 00:00:12.029
汽车 行人和卡车

00:00:12.029 --> 00:00:14.419
我们为其提供两种类型的锚点框

00:00:14.419 --> 00:00:16.155
一个高的锚点框和一个宽的锚点框

00:00:16.155 --> 00:00:20.085
使其能够处理形状不同的重叠对象

00:00:20.085 --> 00:00:22.400
CNN 被训练后

00:00:22.399 --> 00:00:27.129
我们可以向其提供新的测试图像并检测图像中的对象

00:00:27.129 --> 00:00:29.399
测试图像首先被划分为网格

00:00:29.399 --> 00:00:32.369
然后网络生成输出向量

00:00:32.369 --> 00:00:33.890
每个网格单元对应一个向量

00:00:33.890 --> 00:00:36.920
这些向量告诉我们某个单元中是否有对象

00:00:36.920 --> 00:00:38.344
对象的类别是什么

00:00:38.344 --> 00:00:40.615
以及对象的边界框是什么

00:00:40.615 --> 00:00:42.660
因为我们使用两个锚点框

00:00:42.659 --> 00:00:46.114
因此每个网格单元将有两个预测锚点框

00:00:46.115 --> 00:00:51.570
某些（实际上是大部分）预测锚点框的 PC 值将很低

00:00:51.570 --> 00:00:53.570
生成这些输出向量后

00:00:53.570 --> 00:00:58.134
我们使用非最大值抑制删除不太有用的边界框

00:00:58.134 --> 00:01:00.739
对于每个类别 非最大值抑制都会删除

00:01:00.740 --> 00:01:05.150
PC 值低于某个给定阈值的边界框

00:01:05.150 --> 00:01:08.690
然后选择 PC 值最高的边界框

00:01:08.689 --> 00:01:11.810
并删除与该边界框非常相似的边界框

00:01:11.810 --> 00:01:13.549
它将重复这一流程

00:01:13.549 --> 00:01:17.420
直到删除所有类别的非最大值抑制边界框

00:01:17.420 --> 00:01:19.590
最终结果将是这样的

00:01:19.590 --> 00:01:22.010
可以看出 YOLO 有效地检测出

00:01:22.010 --> 00:01:25.870
图像中的很多对象 例如汽车和行人

00:01:25.870 --> 00:01:28.055
你已经知道 YOLO 的工作原理

00:01:28.055 --> 00:01:32.355
可以看出它为何是现今使用最广泛的对象检测算法

00:01:32.355 --> 00:01:36.829
接下来 你将学习 YOLO 算法的代码实现过程

00:01:36.829 --> 00:01:39.019
了解它如何从不同场景中检测对象

00:01:39.019 --> 00:01:43.119
并具有不同的置信水平.
最新课程跟课件还有一对一辅导请加wx：udacity6

