WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:03.750
滑动窗口实施起来非常慢

00:00:03.750 --> 00:00:06.120
但是如果你选择的步长使每个窗口

00:00:06.120 --> 00:00:09.655
都能覆盖图像的一个新区域并且没有重叠的话 速度会更快

00:00:09.654 --> 00:00:11.349
受到此方法的启发

00:00:11.349 --> 00:00:14.439
YOLO 使用网格而不是滑动窗口

00:00:14.439 --> 00:00:16.280
我们来看看原理

00:00:16.280 --> 00:00:19.595
在此示例中 我们使用 7x10 网格

00:00:19.594 --> 00:00:21.024
YOLO 算法使用的网格更精细

00:00:21.024 --> 00:00:24.774
但是整体流程一样

00:00:24.774 --> 00:00:26.129
你可能会疑问

00:00:26.129 --> 00:00:29.224
如何从网格中获得正确的边界框？

00:00:29.225 --> 00:00:32.535
滑动窗口也存在这项挑战

00:00:32.534 --> 00:00:35.339
如何解决这些网格单元

00:00:35.340 --> 00:00:38.030
不太可能与对象边界框匹配这一问题？

00:00:38.030 --> 00:00:42.779
原理是我们可以向每个网格单元分配输出向量

00:00:42.779 --> 00:00:46.675
使每个单元格都具有相关的向量

00:00:46.674 --> 00:00:48.949
这个向量首先告诉我们该单元格中是否有对象

00:00:48.950 --> 00:00:50.470
其次 对象的类别是什么

00:00:50.469 --> 00:00:53.750
第三点是该对象的预测边界框

00:00:53.750 --> 00:00:58.630
这样的话 边界框坐标不需要包含在网格单元中

00:00:58.630 --> 00:01:02.655
假设有一个具有真实标签和边界框的输入图像

00:01:02.655 --> 00:01:04.590
我们可以训练 CNN 为每个网格单元

00:01:04.590 --> 00:01:07.715
生成正确的输出向量

00:01:07.715 --> 00:01:11.930
我们将每个网格单元的输出向量称为 gn

00:01:11.930 --> 00:01:14.610
这个输出向量包含的参数

00:01:14.609 --> 00:01:17.620
与在上个视频中看到的输出向量 y 的一样

00:01:17.620 --> 00:01:21.180
对于第一个单元格 向量 g1 看起来这样

00:01:21.180 --> 00:01:23.800
这个网格单元中没有对象

00:01:23.799 --> 00:01:25.709
因此 pc 等于 0

00:01:25.709 --> 00:01:28.394
类别得分为 0

00:01:28.394 --> 00:01:30.819
方框坐标具有一些值

00:01:30.819 --> 00:01:36.104
这些值的意义不大 因为如果 pc 值太低 我们将丢弃向量

00:01:36.105 --> 00:01:40.915
对于不包含对象的所有网格单元 输出向量都一样

00:01:40.915 --> 00:01:44.870
那么这个人上方的单元格呢？

00:01:44.870 --> 00:01:49.035
这个按网格单元编号的输出向量看起来这样

00:01:49.034 --> 00:01:52.829
pc 等于 1 因为该网格单元中有对象

00:01:52.829 --> 00:01:56.159
c1 等于 1 因为该对象是人

00:01:56.159 --> 00:01:58.170
输出向量中还包含

00:01:58.170 --> 00:02:00.030
预测的边界框坐标

00:02:00.030 --> 00:02:03.075
我们将在后续部分了解如何生成这些值

00:02:03.075 --> 00:02:05.674
我们一直知道 gn 向量是什么样的

00:02:05.674 --> 00:02:08.479
我们将了解如何使用它们训练 CNN

