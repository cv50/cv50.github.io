WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:01.575
From what we've seen,

00:00:01.575 --> 00:00:04.004
YOLO can work well for multiple objects

00:00:04.004 --> 00:00:07.035
where each object is associated with one grid cell.

00:00:07.035 --> 00:00:08.919
But what about in the case of overlap,

00:00:08.919 --> 00:00:13.800
in which one grid cell actually contains the center points of two different objects?

00:00:13.800 --> 00:00:16.440
We can use something called anchor boxes to

00:00:16.440 --> 00:00:19.775
allow one grid cell to detect multiple objects.

00:00:19.774 --> 00:00:24.784
In this image, we see that we have a person and a car overlapping in the image.

00:00:24.785 --> 00:00:26.695
So, part of the car is obscured.

00:00:26.695 --> 00:00:29.800
We can also see that the centers of both bounding boxes,

00:00:29.800 --> 00:00:33.100
the car, and the pedestrian fall in the same grid cell.

00:00:33.100 --> 00:00:37.125
Since the output vector of each grid cell can only have one class,

00:00:37.125 --> 00:00:40.960
then it will be forced to pick either the car or the person.

00:00:40.960 --> 00:00:43.105
But by defining anchor boxes,

00:00:43.104 --> 00:00:45.519
we can create a longer grid cell vector

00:00:45.520 --> 00:00:48.695
and associate multiple classes with each grid cell.

00:00:48.695 --> 00:00:53.534
So, let's define two anchor boxes with some initial width and height.

00:00:53.534 --> 00:00:57.734
In practice, you can define as many anchor boxes as you want.

00:00:57.734 --> 00:01:01.954
You can imagine that these boxes are two different shapes for gift boxes.

00:01:01.954 --> 00:01:06.810
You typically choose gift boxes so that the nicely fit any object you put in them,

00:01:06.810 --> 00:01:09.210
and we wanted to find anchor boxes so that they

00:01:09.209 --> 00:01:12.349
span the variety of object shapes we want to detect.

00:01:12.349 --> 00:01:15.719
Anchor boxes have a defined aspect ratio,

00:01:15.719 --> 00:01:20.075
and they tried to detect objects that nicely fit into a box with that ratio.

00:01:20.075 --> 00:01:24.659
For example, since we're detecting a wide car and a standing person,

00:01:24.659 --> 00:01:28.349
we'll define one anchor box that is roughly the shape of a car,

00:01:28.349 --> 00:01:30.869
this box will be wider than it is tall.

00:01:30.870 --> 00:01:35.025
And we'll define another anchor box that can fit a standing person inside of it,

00:01:35.025 --> 00:01:37.170
which will be taller than it is wide.

00:01:37.170 --> 00:01:42.704
We can now modify the output vector of each grid cell to contain both anchor boxes,

00:01:42.704 --> 00:01:44.760
which have coordinates and class scores.

00:01:44.760 --> 00:01:48.650
So, the output vector will now contain 16 elements.

00:01:48.650 --> 00:01:52.230
The first eight elements will correspond to anchor box one,

00:01:52.230 --> 00:01:55.109
and the last eight will correspond to anchor box two.

00:01:55.109 --> 00:02:00.575
Now, because the bounding box around the car has a higher IOU with anchor box one,

00:02:00.575 --> 00:02:03.370
the anchor one elements of our output vector will include

00:02:03.370 --> 00:02:06.775
the classification and box parameters of the car.

00:02:06.775 --> 00:02:12.055
Similarly, since the bounding box around the person has a higher IOU with anchor box two,

00:02:12.055 --> 00:02:15.969
the anchor two elements will include the parameters of the person.

00:02:15.969 --> 00:02:21.098
It's very challenging even for humans to identify overlapping objects in a scene,

00:02:21.098 --> 00:02:24.549
and anchor boxes give us a way to do this, which is pretty cool.

00:02:24.550 --> 00:02:27.100
But as with any object detection method,

00:02:27.099 --> 00:02:28.674
it has its limitations.

00:02:28.675 --> 00:02:31.825
Consider the case of two overlapping people,

00:02:31.824 --> 00:02:34.299
this algorithm will check which present fits with

00:02:34.300 --> 00:02:37.515
anchor box one and which one fits with anchor box two.

00:02:37.514 --> 00:02:41.529
It can only associate one object with each type of anchor box,

00:02:41.530 --> 00:02:42.969
so it doesn't work very well if you have

00:02:42.969 --> 00:02:46.009
two overlapping objects that are roughly the same shape.

00:02:46.009 --> 00:02:51.274
Similarly, if you only define two anchor boxes but have three overlapping objects,

00:02:51.275 --> 00:02:55.849
then this algorithm fails because it will be forced to identify only two of the objects.

00:02:55.849 --> 00:02:59.134
The good news is that the above cases are somewhat rare.

00:02:59.134 --> 00:03:02.079
In the next video, we'll see how YOLO puts all these techniques

00:03:02.080 --> 00:03:06.440
together and performs object detection for a complex image.

