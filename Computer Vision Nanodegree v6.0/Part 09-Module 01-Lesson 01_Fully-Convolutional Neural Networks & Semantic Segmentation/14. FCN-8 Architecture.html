<!-- udacimak v1.4.4 -->
<!DOCTYPE html>
<html lang="en">
 <head>
  <meta charset="utf-8"/>
  <meta content="width=device-width, initial-scale=1.0" name="viewport"/>
  <meta content="ie=edge" http-equiv="X-UA-Compatible"/>
  <title>
   FCN-8 Architecture
  </title>
  <link href="../assets/css/bootstrap.min.css" rel="stylesheet"/>
  <link href="../assets/css/plyr.css" rel="stylesheet"/>
  <link href="../assets/css/katex.min.css" rel="stylesheet"/>
  <link href="../assets/css/jquery.mCustomScrollbar.min.css" rel="stylesheet"/>
  <link href="../assets/css/styles.css" rel="stylesheet"/>
  <link href="../assets/img/udacimak.png" rel="shortcut icon" type="image/png">
  </link>
 </head>
 <body>
  <div class="wrapper">
   <nav id="sidebar">
    <div class="sidebar-header">
     <h3>
      Fully-Convolutional Neural Networks &amp; Semantic Segmentation
     </h3>
    </div>
    <ul class="sidebar-list list-unstyled CTAs">
     <li>
      <a class="article" href="../index.html">
       Back to Home
      </a>
     </li>
    </ul>
    <ul class="sidebar-list list-unstyled components">
     <li class="">
      <a href="01. Intro.html">
       01. Intro
      </a>
     </li>
     <li class="">
      <a href="02. Why Fully Convolutional Networks (FCNs) .html">
       02. Why Fully Convolutional Networks (FCNs) ?
      </a>
     </li>
     <li class="">
      <a href="03. Fully Convolutional Networks.html">
       03. Fully Convolutional Networks
      </a>
     </li>
     <li class="">
      <a href="04. Fully Connected to 1x1 Convolution.html">
       04. Fully Connected to 1x1 Convolution
      </a>
     </li>
     <li class="">
      <a href="05. Transposed Convolutions.html">
       05. Transposed Convolutions
      </a>
     </li>
     <li class="">
      <a href="06. Skip Connections.html">
       06. Skip Connections
      </a>
     </li>
     <li class="">
      <a href="07. FCNs In The Wild.html">
       07. FCNs In The Wild
      </a>
     </li>
     <li class="">
      <a href="08. Bounding Boxes.html">
       08. Bounding Boxes
      </a>
     </li>
     <li class="">
      <a href="09. Semantic Segmentation.html">
       09. Semantic Segmentation
      </a>
     </li>
     <li class="">
      <a href="10. Semantic Segmentation and FCN's.html">
       10. Semantic Segmentation and FCN's
      </a>
     </li>
     <li class="">
      <a href="11. Scene Understanding.html">
       11. Scene Understanding
      </a>
     </li>
     <li class="">
      <a href="12. IoU.html">
       12. IoU
      </a>
     </li>
     <li class="">
      <a href="13. IOU Example.html">
       13. IOU Example
      </a>
     </li>
     <li class="">
      <a href="14. FCN-8 Architecture.html">
       14. FCN-8 Architecture
      </a>
     </li>
     <li class="">
      <a href="15. Outro.html">
       15. Outro
      </a>
     </li>
    </ul>
    <ul class="sidebar-list list-unstyled CTAs">
     <li>
      <a class="article" href="../index.html">
       Back to Home
      </a>
     </li>
    </ul>
   </nav>
   <div id="content">
    <header class="container-fluild header">
     <div class="container">
      <div class="row">
       <div class="col-12">
        <div class="align-items-middle">
         <button class="btn btn-toggle-sidebar" id="sidebarCollapse" type="button">
          <div>
          </div>
          <div>
          </div>
          <div>
          </div>
         </button>
         <h1 style="display: inline-block">
          14. FCN-8 Architecture
         </h1>
        </div>
       </div>
      </div>
     </div>
    </header>
    <main class="container">
     <div class="row">
      <div class="col-12">
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <h1 id="fcn-8-architecture">
          FCN-8, Architecture
         </h1>
         <p>
          Let’s focus on a concrete implementation of a fully convolutional network. We’ll discuss the
          <a href="https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf" rel="noopener noreferrer" target="_blank">
           FCN-8 architecture
          </a>
          developed at Berkeley. In fact, many FCN models are derived from this FCN-8 implementation. The encoder for FCN-8 is the VGG16 model pretrained on ImageNet for classification. The fully-connected "score" layers are replaced by 1-by-1 convolutions. The code for  convolutional score layer like looks like:
         </p>
         <pre><code>self.score = nn.Conv2d(input_size, num_classes, 1)</code></pre>
         <p>
          The complete architecture is pictured below.
         </p>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <figure class="figure">
          <img alt="" class="img img-fluid" src="img/screen-shot-2018-05-31-at-4.17.51-pm.png"/>
          <figcaption class="figure-caption">
          </figcaption>
         </figure>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <p>
          There are skip connections and various upsampling layers to keep track of a variety of spatial information. In practice this network is often broken down into the
          <strong>
           encoder
          </strong>
          portion with parameters from VGG net, and a decoder portion, which includes the upsampling layers.
         </p>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <h1 id="fcn-8-decoder-portion">
          FCN-8, Decoder Portion
         </h1>
         <p>
          To build the decoder portion of FCN-8, we’ll upsample the input, that comes out of the convolutional layers taken from VGG net, to the original image size. The shape of the tensor after the final convolutional transpose layer will be 4-dimensional: (batch_size, original_height, original_width, num_classes).
         </p>
         <p>
          To define a transposed convolutional layer for upsampling, we can write the following code, where 3 is the size of the convolving kernel:
         </p>
         <pre><code>self.transpose = nn.ConvTranspose2d(input_depth, num_classes, 3, stride=2)</code></pre>
         <p>
          The transpose convolutional layers increase the height and width dimensions of the 4D input Tensor. And you can look at the
          <a href="https://pytorch.org/docs/stable/nn.html#convtranspose2d" rel="noopener noreferrer" target="_blank">
           PyTorch documentation, here
          </a>
          .
         </p>
         <h2 id="skip-connections">
          Skip Connections
         </h2>
         <p>
          The final step is adding skip connections to the model. In order to do this we’ll combine the output of two layers. The first output is the output of the current layer. The second output is the output of a layer further back in the network, typically a pooling layer.
         </p>
         <p>
          In the following example we combine the result of the previous layer with the result of the 4th pooling layer through elementwise addition (
          <code>
           tf.add
          </code>
          ).
         </p>
         <pre><code class="python language-python"># the shapes of these two layers must be the same to add them
input = input + pool_4</code></pre>
         <p>
          We can then follow this with a call to our transpose layer.
         </p>
         <pre><code class="python language-python">input = self.transpose(input)</code></pre>
         <p>
          We can repeat this process, upsampling and creating the necssary skip connections, until the network is complete!
         </p>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <p>
          # FCN-8, Classification &amp; Loss
          <br/>
          The final step is to define a loss. That way, we can approach training a FCN just like we would approach training a normal classification CNN.
         </p>
         <p>
          In the case of a FCN, the goal is to assign each pixel to the appropriate class. We already happen to know a great loss function for this setup, cross entropy loss!
         </p>
         <p>
          Remember the output tensor is 4D so before we perform the loss, we have to reshape it to 2D, where each row represents a pixel and each column a class. From here we can just use standard cross entropy loss.
         </p>
         <p>
          That’s it, we now have an idea of how to create an end-to-end model for semantic segmentation. Check out the original paper to read more specifics about FCN-8.
         </p>
        </div>
       </div>
       <div class="divider">
       </div>
      </div>
      <div class="col-12">
       <p class="text-right">
        <a class="btn btn-outline-primary mt-4" href="15. Outro.html" role="button">
         Next Concept
        </a>
       </p>
      </div>
     </div>
    </main>
    <footer class="footer">
     <div class="container">
      <div class="row">
       <div class="col-12">
        <p class="text-center">
         If you need the newest courses Plase add me wechat: udacity6
        </p>
       </div>
      </div>
     </div>
    </footer>
   </div>
  </div>
  <script src="../assets/js/jquery-3.3.1.min.js">
  </script>
  <script src="../assets/js/plyr.polyfilled.min.js">
  </script>
  <script src="../assets/js/bootstrap.min.js">
  </script>
  <script src="../assets/js/jquery.mCustomScrollbar.concat.min.js">
  </script>
  <script src="../assets/js/katex.min.js">
  </script>
  <script>
   // Initialize Plyr video players
    const players = Array.from(document.querySelectorAll('video')).map(p => new Plyr(p));

    // render math equations
    let elMath = document.getElementsByClassName('mathquill');
    for (let i = 0, len = elMath.length; i < len; i += 1) {
      const el = elMath[i];

      katex.render(el.textContent, el, {
        throwOnError: false
      });
    }

    // this hack will make sure Bootstrap tabs work when using Handlebars
    if ($('#question-tabs').length && $('#user-answer-tabs').length) {
      $("#question-tabs a.nav-link").on('click', function () {
        $("#question-tab-contents .tab-pane").hide();
        $($(this).attr("href")).show();
      });
      $("#user-answer-tabs a.nav-link").on('click', function () {
        $("#user-answer-tab-contents .tab-pane").hide();
        $($(this).attr("href")).show();
      });
    } else {
      $("a.nav-link").on('click', function () {
        $(".tab-pane").hide();
        $($(this).attr("href")).show();
      });
    }

    // side bar events
    $(document).ready(function () {
      $("#sidebar").mCustomScrollbar({
        theme: "minimal"
      });

      $('#sidebarCollapse').on('click', function () {
        $('#sidebar, #content').toggleClass('active');
        $('.collapse.in').toggleClass('in');
        $('a[aria-expanded=true]').attr('aria-expanded', 'false');
      });

      // scroll to first video on page loading
      if ($('video').length) {
        $('html,body').animate({ scrollTop: $('div.plyr').prev().offset().top});
      }

      // auto play first video: this may not work with chrome/safari due to autoplay policy
      if (players && players.length > 0) {
        players[0].play();
      }

      // scroll sidebar to current concept
      const currentInSideBar = $( "ul.sidebar-list.components li a:contains('14. FCN-8 Architecture')" )
      currentInSideBar.css( "text-decoration", "underline" );
      $("#sidebar").mCustomScrollbar('scrollTo', currentInSideBar);
    });
  </script>
 </body>
</html>
