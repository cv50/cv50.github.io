<!-- udacimak v1.4.4 -->
<!DOCTYPE html>
<html lang="en">
 <head>
  <meta charset="utf-8"/>
  <meta content="width=device-width, initial-scale=1.0" name="viewport"/>
  <meta content="ie=edge" http-equiv="X-UA-Compatible"/>
  <title>
   Semantic Segmentation and FCN's
  </title>
  <link href="../assets/css/bootstrap.min.css" rel="stylesheet"/>
  <link href="../assets/css/plyr.css" rel="stylesheet"/>
  <link href="../assets/css/katex.min.css" rel="stylesheet"/>
  <link href="../assets/css/jquery.mCustomScrollbar.min.css" rel="stylesheet"/>
  <link href="../assets/css/styles.css" rel="stylesheet"/>
  <link href="../assets/img/udacimak.png" rel="shortcut icon" type="image/png">
  </link>
 </head>
 <body>
  <div class="wrapper">
   <nav id="sidebar">
    <div class="sidebar-header">
     <h3>
      Fully-Convolutional Neural Networks &amp; Semantic Segmentation
     </h3>
    </div>
    <ul class="sidebar-list list-unstyled CTAs">
     <li>
      <a class="article" href="../index.html">
       Back to Home
      </a>
     </li>
    </ul>
    <ul class="sidebar-list list-unstyled components">
     <li class="">
      <a href="01. Intro.html">
       01. Intro
      </a>
     </li>
     <li class="">
      <a href="02. Why Fully Convolutional Networks (FCNs) .html">
       02. Why Fully Convolutional Networks (FCNs) ?
      </a>
     </li>
     <li class="">
      <a href="03. Fully Convolutional Networks.html">
       03. Fully Convolutional Networks
      </a>
     </li>
     <li class="">
      <a href="04. Fully Connected to 1x1 Convolution.html">
       04. Fully Connected to 1x1 Convolution
      </a>
     </li>
     <li class="">
      <a href="05. Transposed Convolutions.html">
       05. Transposed Convolutions
      </a>
     </li>
     <li class="">
      <a href="06. Skip Connections.html">
       06. Skip Connections
      </a>
     </li>
     <li class="">
      <a href="07. FCNs In The Wild.html">
       07. FCNs In The Wild
      </a>
     </li>
     <li class="">
      <a href="08. Bounding Boxes.html">
       08. Bounding Boxes
      </a>
     </li>
     <li class="">
      <a href="09. Semantic Segmentation.html">
       09. Semantic Segmentation
      </a>
     </li>
     <li class="">
      <a href="10. Semantic Segmentation and FCN's.html">
       10. Semantic Segmentation and FCN's
      </a>
     </li>
     <li class="">
      <a href="11. Scene Understanding.html">
       11. Scene Understanding
      </a>
     </li>
     <li class="">
      <a href="12. IoU.html">
       12. IoU
      </a>
     </li>
     <li class="">
      <a href="13. IOU Example.html">
       13. IOU Example
      </a>
     </li>
     <li class="">
      <a href="14. FCN-8 Architecture.html">
       14. FCN-8 Architecture
      </a>
     </li>
     <li class="">
      <a href="15. Outro.html">
       15. Outro
      </a>
     </li>
    </ul>
    <ul class="sidebar-list list-unstyled CTAs">
     <li>
      <a class="article" href="../index.html">
       Back to Home
      </a>
     </li>
    </ul>
   </nav>
   <div id="content">
    <header class="container-fluild header">
     <div class="container">
      <div class="row">
       <div class="col-12">
        <div class="align-items-middle">
         <button class="btn btn-toggle-sidebar" id="sidebarCollapse" type="button">
          <div>
          </div>
          <div>
          </div>
          <div>
          </div>
         </button>
         <h1 style="display: inline-block">
          10. Semantic Segmentation and FCN's
         </h1>
        </div>
       </div>
      </div>
     </div>
    </header>
    <main class="container">
     <div class="row">
      <div class="col-12">
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <h2 id="semantic-segmentation">
          Semantic Segmentation
         </h2>
         <p>
          In semantic segmentation, we want to input an image into a neural network and we want to output a category for
          <strong>
           every pixel
          </strong>
          in this image. For example, for the below image of a couple of cows, we want to look at every pixel and decide: is that pixel part of a cow, the grass or sky, or some other category?
         </p>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <figure class="figure">
          <img alt="Small image of cows in a field." class="img img-fluid" src="img/screen-shot-2018-05-31-at-3.54.39-pm.png"/>
          <figcaption class="figure-caption">
           <p>
            Small image of cows in a field.
           </p>
          </figcaption>
         </figure>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <p>
          We’ll have a discrete set of categories, much like in a classification task. But instead of assigning a single class to an image, we want to assign a class to every pixel in that image. So, how do we approach this task?
         </p>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <h2 id="fully-convolutional-network-fcn-approach">
          Fully-Convolutional Network (FCN) Approach
         </h2>
         <p>
          If your goal is to preserve the spatial information in our original input image, you might think about the simplest solution: simply never discard any of that information; never downsample/maxpool and don’t add a fully-connected layer at the end of the network.
         </p>
         <p>
          We could use a network made entirely of convolutional layers to do this, something called a fully convolutional neural network.
          <strong>
           A fully convolutional neural network preserves spatial information.
          </strong>
         </p>
         <p>
          This network would take in an image that has true labels attached to each pixel, so every pixel is labeled as grass or cat or sky, and so on. Then we pass that input through a stack of convolutional layers that preserve the spatial size of the input (something like 3x3 kernels with zero padding). Then, the final convolutional layer outputs a tensor that has dimensions CxHxW, where C is the number of categories we have.
         </p>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <figure class="figure">
          <img alt="FCN architecture." class="img img-fluid" src="img/screen-shot-2018-05-31-at-4.04.15-pm.png"/>
          <figcaption class="figure-caption">
           <p>
            FCN architecture.
           </p>
          </figcaption>
         </figure>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <h3 id="predictions">
          Predictions
         </h3>
         <p>
          This output Tensor of predictions contains values that classify every pixel in the image, so if we look at a single pixel in this output, we would see a vector that looks like a classification vector -- with values in it that show the probability of this single pixel being a cat or grass or sky, and so on. We could do this pixel level classification all at once, and then train this network by assigning a loss function to each pixel in the image and doing backpropagation as usual. So, if the network makes an error and classifies a single pixel incorrectly, it will go back and adjust the weights in the convolutional layers until that error is reduced.
         </p>
         <h3 id="limitations-of-this-approach">
          Limitations of This Approach
         </h3>
         <ul>
          <li>
           It's very expensive to label this data (you have to label every pixel), and
          </li>
          <li>
           It's computationally expensive to maintain spatial information in each convolutional layer
          </li>
         </ul>
         <p>
          So…
         </p>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <h2 id="downsamplingupsampling">
          Downsampling/Upsampling
         </h2>
         <p>
          Instead, what you usually see is an architecture that uses downsampling of a feature map and an upsampling layer to reduce the dimensionality and, therefore, the  computational cost, of moving forward through these layers in the middle of the network.
         </p>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <figure class="figure">
          <img alt="Downsampling/upsampling an an FCN." class="img img-fluid" src="img/screen-shot-2018-05-31-at-4.02.08-pm.png"/>
          <figcaption class="figure-caption">
           <p>
            Downsampling/upsampling an an FCN.
           </p>
          </figcaption>
         </figure>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <p>
          So, what you’ll see in these networks is a couple of convolutional layers followed by downsampling done by something like maxpooling, very similar to a simple image classification network. Only, this time, in the second half of the network, we want to increase the spatial resolution, so that our output is the same size as the input image, with a label for every pixel in the original image.
         </p>
        </div>
       </div>
       <div class="divider">
       </div>
      </div>
      <div class="col-12">
       <p class="text-right">
        <a class="btn btn-outline-primary mt-4" href="11. Scene Understanding.html" role="button">
         Next Concept
        </a>
       </p>
      </div>
     </div>
    </main>
    <footer class="footer">
     <div class="container">
      <div class="row">
       <div class="col-12">
        <p class="text-center">
         If you need the newest courses Plase add me wechat: udacity6
        </p>
       </div>
      </div>
     </div>
    </footer>
   </div>
  </div>
  <script src="../assets/js/jquery-3.3.1.min.js">
  </script>
  <script src="../assets/js/plyr.polyfilled.min.js">
  </script>
  <script src="../assets/js/bootstrap.min.js">
  </script>
  <script src="../assets/js/jquery.mCustomScrollbar.concat.min.js">
  </script>
  <script src="../assets/js/katex.min.js">
  </script>
  <script>
   // Initialize Plyr video players
    const players = Array.from(document.querySelectorAll('video')).map(p => new Plyr(p));

    // render math equations
    let elMath = document.getElementsByClassName('mathquill');
    for (let i = 0, len = elMath.length; i < len; i += 1) {
      const el = elMath[i];

      katex.render(el.textContent, el, {
        throwOnError: false
      });
    }

    // this hack will make sure Bootstrap tabs work when using Handlebars
    if ($('#question-tabs').length && $('#user-answer-tabs').length) {
      $("#question-tabs a.nav-link").on('click', function () {
        $("#question-tab-contents .tab-pane").hide();
        $($(this).attr("href")).show();
      });
      $("#user-answer-tabs a.nav-link").on('click', function () {
        $("#user-answer-tab-contents .tab-pane").hide();
        $($(this).attr("href")).show();
      });
    } else {
      $("a.nav-link").on('click', function () {
        $(".tab-pane").hide();
        $($(this).attr("href")).show();
      });
    }

    // side bar events
    $(document).ready(function () {
      $("#sidebar").mCustomScrollbar({
        theme: "minimal"
      });

      $('#sidebarCollapse').on('click', function () {
        $('#sidebar, #content').toggleClass('active');
        $('.collapse.in').toggleClass('in');
        $('a[aria-expanded=true]').attr('aria-expanded', 'false');
      });

      // scroll to first video on page loading
      if ($('video').length) {
        $('html,body').animate({ scrollTop: $('div.plyr').prev().offset().top});
      }

      // auto play first video: this may not work with chrome/safari due to autoplay policy
      if (players && players.length > 0) {
        players[0].play();
      }

      // scroll sidebar to current concept
      const currentInSideBar = $( "ul.sidebar-list.components li a:contains('10. Semantic Segmentation and FCN&#x27;s')" )
      currentInSideBar.css( "text-decoration", "underline" );
      $("#sidebar").mCustomScrollbar('scrollTo', currentInSideBar);
    });
  </script>
 </body>
</html>
