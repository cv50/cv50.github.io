WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:04.080
在训练 CNN 对一组图像进行分类时

00:00:04.080 --> 00:00:06.390
我们通过比较输出的预测类别和真实类别标签

00:00:06.389 --> 00:00:09.929
并查看二者是否匹配来训练 CNN

00:00:09.929 --> 00:00:12.629
我们通常使用交叉熵

00:00:12.630 --> 00:00:15.480
衡量这些类别之间的误差

00:00:15.480 --> 00:00:18.570
因为当具有不确定性的预测类别与真实类别标签越来越接近时

00:00:18.570 --> 00:00:22.500
交叉熵损失会逐渐降低

00:00:22.500 --> 00:00:25.350
但是当我们比较一组点时

00:00:25.350 --> 00:00:30.510
例如脸部位置/点或定义图像特定区域的点

00:00:30.510 --> 00:00:34.905
我们需要一种衡量这些坐标值之间相似性的损失函数

00:00:34.905 --> 00:00:37.289
这不是分类问题

00:00:37.289 --> 00:00:38.939
而是回归问题

00:00:38.939 --> 00:00:40.710
分类是预测类别标签

00:00:40.710 --> 00:00:44.484
回归是预测数量

00:00:44.484 --> 00:00:48.479
对于回归问题 例如预测 (x,y) 坐标

00:00:48.479 --> 00:00:50.489
我们需要一个损失函数来比较这些数量

00:00:50.490 --> 00:00:54.164
并衡量它们之间的近似程度

00:00:54.164 --> 00:00:57.550
有意思的是 对于分类问题

00:00:57.549 --> 00:00:59.674
我们知道准确率是什么

00:00:59.674 --> 00:01:04.359
如果预测类别与真实类别匹配 则模型是准确的

00:01:04.359 --> 00:01:05.819
但是对于回归问题

00:01:05.819 --> 00:01:08.414
我们无法说一个点是否准确

00:01:08.415 --> 00:01:11.040
我们只能通过衡量点之间的均方误差等

00:01:11.040 --> 00:01:13.955
来评估数量

00:01:13.954 --> 00:01:15.500
对于回归问题

00:01:15.500 --> 00:01:20.385
我们经常讨论的是模型的误差是否很小 而不是模型是否准确

00:01:20.385 --> 00:01:23.320
要衡量两个数量之间的误差

00:01:23.319 --> 00:01:26.169
我们可以使用几种不同的损失函数

00:01:26.170 --> 00:01:29.489
最简单的是 L1 损失

00:01:29.489 --> 00:01:33.359
它衡量的是预测输出（称为 p）和目标 (t)

00:01:33.359 --> 00:01:35.870
之间元素级别的差异

00:01:35.870 --> 00:01:41.160
假设我们仅预测一个点 p 坐标 (x,y) 表示图像中对象的中心

00:01:41.159 --> 00:01:45.469
在此示例中 损失函数将查看 CNN 生成的预测点 p

00:01:45.469 --> 00:01:50.254
和对象的真实中心目标位置 t

00:01:50.254 --> 00:01:52.549
L1 损失将返回一个

00:01:52.549 --> 00:01:55.974
表示预测点和真实点之间距离的值

00:01:55.974 --> 00:01:58.530
还可以使用 MSE 损失

00:01:58.530 --> 00:02:00.920
它衡量的是预测 p 中的元素

00:02:00.920 --> 00:02:04.019
和目标 t 中的元素之间的均方误差

00:02:04.019 --> 00:02:07.339
这两种方法都适合衡量点之间的距离

00:02:07.340 --> 00:02:11.275
但是所有损失函数都具有优势和弊端

00:02:11.275 --> 00:02:15.039
你需要考虑的是 L1 损失可能会忽略小的误差值

00:02:15.039 --> 00:02:20.169
而 MSE 损失对大的误差值最敏感

00:02:20.169 --> 00:02:24.250
导致可能会放大很大但是不常见的误差

00:02:24.250 --> 00:02:26.185
称之为离群值

00:02:26.185 --> 00:02:31.120
还有 Smooth L1 损失 对于预测值和真实值之间很小的差异

00:02:31.120 --> 00:02:37.094
它会使用均方误差函数 而对于很大的误差 则使用 L1 损失

00:02:37.094 --> 00:02:42.770
Smooth L1 损失尝试利用 MSE 和 L1 损失的优势

00:02:42.770 --> 00:02:45.850
你可以自己尝试下这些不同的损失函数

00:02:45.849 --> 00:02:47.870
看看它们在训练期间是如何降低的

00:02:47.870 --> 00:02:50.800
并为给定回归任务选择最佳损失函数

