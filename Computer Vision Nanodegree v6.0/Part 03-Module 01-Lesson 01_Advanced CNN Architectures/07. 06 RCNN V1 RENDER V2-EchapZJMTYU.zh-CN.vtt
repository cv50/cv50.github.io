WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:03.700
要定位并分类图像中的多个对象

00:00:03.700 --> 00:00:08.830
我们希望能够识别有限数量的裁剪区域供 CNN 查看

00:00:08.830 --> 00:00:10.214
在理想情况下

00:00:10.214 --> 00:00:12.675
我们将为图像中的三个不同对象

00:00:12.675 --> 00:00:14.910
生成三个完美裁剪的区域

00:00:14.910 --> 00:00:19.199
为了实现这一目标并生成数量合理的裁剪区域

00:00:19.199 --> 00:00:21.894
诞生了候选区域的概念

00:00:21.894 --> 00:00:25.800
候选区域使我们能够快速查看图像

00:00:25.800 --> 00:00:29.679
并仅为我们认为可能存在对象的部分生成区域

00:00:29.679 --> 00:00:34.329
我们可以使用传统计算机视觉技巧检测边缘和纹理 Blob 等

00:00:34.329 --> 00:00:39.879
生成一组最后可能在其中发现对象的区域

00:00:39.880 --> 00:00:44.320
例如具有相似纹理的区域或相同的统一边界的区域

00:00:44.320 --> 00:00:48.670
这些建议通常会生成有噪非对象区域

00:00:48.670 --> 00:00:52.960
但是也非常有可能包含具有对象的区域

00:00:52.960 --> 00:00:57.469
因此噪点是值得考虑的 以防止忽略任何对象

00:00:57.469 --> 00:01:01.700
我们来看看此方法在 CNN 架构中的样貌如何

00:01:01.700 --> 00:01:06.704
我们可以使用候选区域算法生成一组有限的裁剪区域

00:01:06.704 --> 00:01:10.170
通常称之为感兴趣区域 (ROI)

00:01:10.170 --> 00:01:13.489
然后将这些区域挨个地传入分类 CNN 中

00:01:13.489 --> 00:01:18.359
看看网络对每个裁剪区域预测出什么样的分类标签

00:01:18.359 --> 00:01:20.864
这种模型称为 R-CNN

00:01:20.864 --> 00:01:23.929
是区域卷积神经网络的简称

00:01:23.930 --> 00:01:27.720
R-CNN 为每个感兴趣区域生成一个类别

00:01:27.719 --> 00:01:32.120
因此可以识别图像中有狗的区域和有猫的区域

00:01:32.120 --> 00:01:35.160
在此示例中 我们还包含了一个类别 叫做背景

00:01:35.159 --> 00:01:37.539
用于捕获任何有噪区域

00:01:37.540 --> 00:01:41.719
因为这些区域通常具有不同的大小 因此首先需要被转换成标准大小

00:01:41.719 --> 00:01:45.875
使 CNN 能够接受为输入图像

00:01:45.875 --> 00:01:51.109
这个方法的主要缺点是依然很耗时

00:01:51.109 --> 00:01:53.269
因为需要将每个裁剪区域传入整个 CNN 中

00:01:53.269 --> 00:01:56.804
然后才能生成一个类别标签

00:01:56.805 --> 00:02:00.890
接下来 我们将了解一些区域 CNN 示例

00:02:00.890 --> 00:02:05.079
这些 CNN 的目标是加速这一流程并有效分类图像中的多个对象

