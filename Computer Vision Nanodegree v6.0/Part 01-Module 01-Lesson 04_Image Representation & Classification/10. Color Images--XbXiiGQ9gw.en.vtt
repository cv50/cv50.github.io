WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:03.640
Now you've seen an example of an image broken down into

00:00:03.640 --> 00:00:07.990
a 2D grid of grayscale pixel values that has a width and a height,

00:00:07.990 --> 00:00:10.164
but color images are little different.

00:00:10.164 --> 00:00:16.074
Color images are interpreted as 3D cubes of values with width, height, and depth.

00:00:16.074 --> 00:00:18.974
The depth is the number of color channels.

00:00:18.975 --> 00:00:23.455
Most color images can be represented by combinations of only three colors,

00:00:23.454 --> 00:00:25.704
red, green, and blue values.

00:00:25.704 --> 00:00:31.339
These are known as RGB images and for RGB images the depth is three.

00:00:31.339 --> 00:00:35.994
It's helpful to think of the depth as three stacked 2D colored layers.

00:00:35.994 --> 00:00:39.039
One layer is red, one green, and one blue.

00:00:39.039 --> 00:00:42.935
And when stacked together they create a complete color image.

00:00:42.935 --> 00:00:45.640
Now, color images contain more information than

00:00:45.640 --> 00:00:47.814
grayscale images and they can add

00:00:47.814 --> 00:00:51.009
unnecessary complexity and take up more space in memory.

00:00:51.009 --> 00:00:55.969
However, color images are also really useful for certain classification tasks.

00:00:55.969 --> 00:01:00.174
For example, say you want to classify lane lines in this image of a road.

00:01:00.174 --> 00:01:03.429
One of these lines is yellow and one is white, but which is which?

00:01:03.429 --> 00:01:07.359
You might see a slight difference in the grayscale intensity of

00:01:07.359 --> 00:01:09.400
the lane lines but the difference is so

00:01:09.400 --> 00:01:12.190
small and it varies under different lighting conditions.

00:01:12.189 --> 00:01:14.409
So this grayscale image does not provide

00:01:14.409 --> 00:01:18.259
enough information to distinguish between the yellow and white lane lines.

00:01:18.260 --> 00:01:20.730
Let's see the color image for comparison.

00:01:20.730 --> 00:01:24.490
Here we can clearly see the difference between the white and yellow lane lines.

00:01:24.489 --> 00:01:27.899
And so we can tell the machine to recognize this difference too.

00:01:27.900 --> 00:01:31.779
So because this identification task is dependent on color,

00:01:31.778 --> 00:01:34.369
it's important that we work with color images.

00:01:34.370 --> 00:01:35.829
In general, when you think of

00:01:35.829 --> 00:01:39.939
a computer vision application like identifying lane lines or cars or people,

00:01:39.939 --> 00:01:43.810
you can decide whether color information and color images are useful,

00:01:43.810 --> 00:01:45.790
by thinking about your own vision.

00:01:45.790 --> 00:01:50.080
If the identification problem is easier in color for us humans,

00:01:50.079 --> 00:01:54.010
it's likely easier for an algorithm to see color images too.

