WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:03.240
After exploring the day and night image data,

00:00:03.240 --> 00:00:06.460
you may have noticed a part of the data that we haven't yet gone over.

00:00:06.459 --> 00:00:09.015
A label associated with each image.

00:00:09.015 --> 00:00:10.890
So, what exactly is a label?

00:00:10.890 --> 00:00:12.150
And why do we need It?

00:00:12.150 --> 00:00:16.690
A label is kind of like a tag that's attached to a specific image.

00:00:16.690 --> 00:00:19.185
And that tells you something about that image.

00:00:19.184 --> 00:00:22.410
You can think of a label sort of like a name tag.

00:00:22.410 --> 00:00:24.870
I wear a name tag to events when I meet new people,

00:00:24.870 --> 00:00:27.375
and my name tag labels me as Cezanne.

00:00:27.375 --> 00:00:30.719
Now, an image can have multiple labels that describe it,

00:00:30.719 --> 00:00:32.789
which would be like if I had multiple labels,

00:00:32.789 --> 00:00:34.500
like human or wears glasses,

00:00:34.500 --> 00:00:36.600
that each described something about me.

00:00:36.600 --> 00:00:40.170
But for this lesson, we'll be working with one label per image.

00:00:40.170 --> 00:00:43.365
These labels separate the image data into classes.

00:00:43.365 --> 00:00:46.200
And classes are like general categories.

00:00:46.200 --> 00:00:49.530
So the label for me might be human which is a category distinct

00:00:49.530 --> 00:00:52.905
from a label like a table or a car or any other thing,

00:00:52.905 --> 00:00:55.875
and it's more general than a label like Cezanne.

00:00:55.875 --> 00:00:58.140
So, for the image data sets we work with,

00:00:58.140 --> 00:01:01.049
we should have as many labels as we have classes.

00:01:01.049 --> 00:01:02.969
In the case of our day and night images,

00:01:02.969 --> 00:01:05.640
we have two labels, day and night.

00:01:05.640 --> 00:01:08.055
Now, why do we need these labels?

00:01:08.055 --> 00:01:10.590
You can tell if an image is night or day,

00:01:10.590 --> 00:01:14.250
but a computer cannot unless we tell it explicitly with a label.

00:01:14.250 --> 00:01:16.469
This becomes especially important when we're

00:01:16.469 --> 00:01:19.394
testing the accuracy of a classification model.

00:01:19.394 --> 00:01:22.185
A classifier takes in an image as input,

00:01:22.185 --> 00:01:27.210
ensure the output a predicted label that tells us the predicted class of that image.

00:01:27.209 --> 00:01:29.759
Now, when we load in data like you've seen,

00:01:29.760 --> 00:01:32.490
we load in what are called the true labels.

00:01:32.489 --> 00:01:36.134
And a true label is just the correct label for that image.

00:01:36.135 --> 00:01:38.730
To check the accuracy of our classifier,

00:01:38.730 --> 00:01:41.265
we compare the predicted and true labels.

00:01:41.265 --> 00:01:43.590
If the true and predicted labels match,

00:01:43.590 --> 00:01:45.719
then we've classified the image correctly.

00:01:45.719 --> 00:01:47.849
But sometimes the labels do not match,

00:01:47.849 --> 00:01:50.204
which means we've misclassified an image.

00:01:50.204 --> 00:01:51.750
After looking at many,

00:01:51.750 --> 00:01:54.299
many images the accuracy of a classifier,

00:01:54.299 --> 00:01:57.480
is defined as the number of correctly classified images,

00:01:57.480 --> 00:01:59.865
for which the predicted label matches the true label,

00:01:59.864 --> 00:02:02.474
divided by the total number of images.

00:02:02.474 --> 00:02:06.089
So, say we tried to classify 100 total images,

00:02:06.090 --> 00:02:08.390
and we correctly classified 81 of them,

00:02:08.389 --> 00:02:11.084
meaning we misclassified 19 of them.

00:02:11.085 --> 00:02:15.495
That would mean we'd have 0.81 or 81 percent accuracy,

00:02:15.495 --> 00:02:18.180
and we can only tell a computer to check the accuracy of

00:02:18.180 --> 00:02:21.915
a classifier when we have these predicted and true labels to compare.

00:02:21.914 --> 00:02:25.049
We can also learn from any mistakes the classifier makes,

00:02:25.050 --> 00:02:26.905
as we'll see later in this lesson.

00:02:26.905 --> 00:02:29.039
As a note, it's good practice to use

00:02:29.039 --> 00:02:32.669
numerical labels instead of strings or categorical labels.

00:02:32.669 --> 00:02:35.250
Numbers are easier to track and compare,

00:02:35.250 --> 00:02:37.860
so for our day and night binary class example,

00:02:37.860 --> 00:02:39.790
instead of day and night labels,

00:02:39.789 --> 00:02:43.709
we'll use the numerical labels zero for night, and one for day.

00:02:43.710 --> 00:02:46.980
Okay, now you're familiar with the day and night image data,

00:02:46.979 --> 00:02:49.469
and you know what a label is, and why we use them.

00:02:49.469 --> 00:02:51.254
You're ready for the next steps.

00:02:51.254 --> 00:02:54.585
We'll be building a classification pipeline from start to end.

00:02:54.585 --> 00:02:58.900
Let's first brainstorm what steps we'll take to classify these images.

