WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:04.169
运行程序 发现概率最高的单元格是第四个单元格

00:00:04.169 --> 00:00:08.830
这很合理 因为与红色-红色最匹配的情况

00:00:08.830 --> 00:00:11.564
是这里和这里

00:00:11.564 --> 00:00:13.649
看到第二个红色后

00:00:13.650 --> 00:00:18.425
机器人往右移动一个单位 发现自己位于第四个单元格中 如此处所示

00:00:18.425 --> 00:00:21.300
我要恭喜下大家

00:00:21.300 --> 00:00:24.539
你刚刚编写的代码就是

00:00:24.539 --> 00:00:30.994
实现 Google 无人驾驶汽车定位功能的核心软件部分

00:00:30.995 --> 00:00:33.064
正如我在一开始提到的

00:00:33.064 --> 00:00:35.875
汽车必须精确知道相对于道路地图的位置

00:00:35.875 --> 00:00:39.255
这一点非常重要

00:00:39.255 --> 00:00:42.770
在实际生活中 道路并不是涂成绿色和红色

00:00:42.770 --> 00:00:45.234
而是有道路标线

00:00:45.234 --> 00:00:48.564
不再是这里的绿色和红色单元格

00:00:48.564 --> 00:00:53.920
我们代入道路标线相对于路面颜色的颜色

00:00:53.920 --> 00:00:56.435
不再是一个时间步的观察结果

00:00:56.435 --> 00:00:58.120
而是整个观察结果 整个相机图像

00:00:58.119 --> 00:01:01.909
相机图像也是一样的

00:01:01.909 --> 00:01:03.884
只要将模型中的相机图像

00:01:03.884 --> 00:01:08.019
与测量中的相机图像对应即可

00:01:08.019 --> 00:01:10.149
然后有一段代码

00:01:10.150 --> 00:01:13.500
并不比你编写的复杂很多

00:01:13.500 --> 00:01:17.439
负责定位 Google 无人驾驶汽车

