<!-- udacimak v1.4.4 -->
<!DOCTYPE html>
<html lang="en">
 <head>
  <meta charset="utf-8"/>
  <meta content="width=device-width, initial-scale=1.0" name="viewport"/>
  <meta content="ie=edge" http-equiv="X-UA-Compatible"/>
  <title>
   Facial Keypoint Detection
  </title>
  <link href="../assets/css/bootstrap.min.css" rel="stylesheet"/>
  <link href="../assets/css/plyr.css" rel="stylesheet"/>
  <link href="../assets/css/katex.min.css" rel="stylesheet"/>
  <link href="../assets/css/jquery.mCustomScrollbar.min.css" rel="stylesheet"/>
  <link href="../assets/css/styles.css" rel="stylesheet"/>
  <link href="../assets/img/udacimak.png" rel="shortcut icon" type="image/png">
  </link>
 </head>
 <body>
  <div class="wrapper">
   <nav id="sidebar">
    <div class="sidebar-header">
     <h3>
      Project: Facial Keypoint Detection
     </h3>
    </div>
    <ul class="sidebar-list list-unstyled CTAs">
     <li>
      <a class="article" href="../index.html">
       Back to Home
      </a>
     </li>
    </ul>
    <ul class="sidebar-list list-unstyled components">
     <li class="">
      <a href="01. Project Overview.html">
       01. Project Overview
      </a>
     </li>
     <li class="">
      <a href="02. Workspaces Best Practices.html">
       02. Workspaces: Best Practices
      </a>
     </li>
     <li class="">
      <a href="03. Project Facial Keypoint Detection.html">
       03. Project: Facial Keypoint Detection
      </a>
     </li>
     <li class="">
      <a href="Project Description - Facial Keypoint Detection.html">
       Project Description - Facial Keypoint Detection
      </a>
     </li>
     <li class="">
      <a href="Project Rubric - Facial Keypoint Detection.html">
       Project Rubric - Facial Keypoint Detection
      </a>
     </li>
    </ul>
    <ul class="sidebar-list list-unstyled CTAs">
     <li>
      <a class="article" href="../index.html">
       Back to Home
      </a>
     </li>
    </ul>
   </nav>
   <div id="content">
    <header class="container-fluild header">
     <div class="container">
      <div class="row">
       <div class="col-12">
        <div class="align-items-middle">
         <button class="btn btn-toggle-sidebar" id="sidebarCollapse" type="button">
          <div>
          </div>
          <div>
          </div>
          <div>
          </div>
         </button>
         <h1 style="display: inline-block">
          Facial Keypoint Detection
         </h1>
        </div>
       </div>
      </div>
     </div>
    </header>
    <main class="container">
     <div class="row">
      <div class="col-12">
       <div>
        <h2>
         <p>
          Files Submitted
         </p>
        </h2>
        <table class="table table-bordered table-hover">
         <thead>
          <tr class="thead-dark">
           <th>
            Criteria
           </th>
           <th>
            Meet Specification
           </th>
          </tr>
         </thead>
         <tbody>
          <tr scope="row">
           <td>
            <p>
             Submission Files
            </p>
           </td>
           <td>
            <p>
             The submission includes
             <strong>
              models.py
             </strong>
             and the following Jupyter notebooks, where all questions have been answered and training and visualization cells have been executed:
             <br/>
             <strong>
              2. Define the Network Architecture.ipynb
             </strong>
             , and
             <br/>
             <strong>
              3. Facial Keypoint Detection, Complete Pipeline.ipynb
             </strong>
             .
             <br/>
             Other files may be included, but are not necessary for grading purposes. Note that all your files will be zipped and uploaded should you submit via the provided workspace.
            </p>
           </td>
          </tr>
         </tbody>
        </table>
       </div>
       <div>
        <h2>
         <p>
          <code>
           models.py
          </code>
         </p>
        </h2>
        <table class="table table-bordered table-hover">
         <thead>
          <tr class="thead-dark">
           <th>
            Criteria
           </th>
           <th>
            Meet Specification
           </th>
          </tr>
         </thead>
         <tbody>
          <tr scope="row">
           <td>
            <p>
             Define a CNN in
             <code>
              models.py
             </code>
            </p>
           </td>
           <td>
            <p>
             Define a convolutional neural network with at least one convolutional layer, i.e.
             <code>
              self.conv1 = nn.Conv2d(1, 32, 5)
             </code>
             . The network should take in a grayscale, square image.
            </p>
           </td>
          </tr>
         </tbody>
        </table>
       </div>
       <div>
        <h2>
         <p>
          Notebook 2: Define the Network Architecture
         </p>
        </h2>
        <table class="table table-bordered table-hover">
         <thead>
          <tr class="thead-dark">
           <th>
            Criteria
           </th>
           <th>
            Meet Specification
           </th>
          </tr>
         </thead>
         <tbody>
          <tr scope="row">
           <td>
            <p>
             Define the
             <code>
              data_transform
             </code>
             for training and test data
            </p>
           </td>
           <td>
            <p>
             Define a
             <code>
              data_transform
             </code>
             and apply it whenever you instantiate a DataLoader.  The composed transform should include: rescaling/cropping, normalization, and turning input images into torch Tensors. The transform should turn any input image into a normalized, square, grayscale image and then a Tensor for your model to take it as input.
            </p>
            <p>
             Depending on the complexity of the network you define, and other hyperparameters the model can take some time to train. We encourage you to start with a simple network with only 2 layers. You'll be graded based on the implementation of your models rather than accuracy.
            </p>
           </td>
          </tr>
          <tr scope="row">
           <td>
            <p>
             Define the loss and optimization functions
            </p>
           </td>
           <td>
            <p>
             Select a loss function and optimizer for training the model. The loss and optimization functions should be appropriate for keypoint detection, which is a regression problem.
            </p>
           </td>
          </tr>
          <tr scope="row">
           <td>
            <p>
             Train the CNN
            </p>
           </td>
           <td>
            <p>
             Train your CNN after defining its loss and optimization functions. You are encouraged, but not required, to visualize the loss over time/epochs by printing it out occasionally and/or plotting the loss over time. Save your best trained model.
            </p>
           </td>
          </tr>
          <tr scope="row">
           <td>
            <p>
             Answer questions about model architecture
            </p>
           </td>
           <td>
            <p>
             After training, all 3 questions about model architecture, choice of loss function, and choice of batch_size and epoch parameters are answered.
            </p>
           </td>
          </tr>
          <tr scope="row">
           <td>
            <p>
             Visualize one or more learned feature maps
            </p>
           </td>
           <td>
            <p>
             Your CNN "learns" (updates the weights in its convolutional layers) to recognize features and this criteria requires that you extract at least one convolutional filter from your trained model, apply it to an image, and see what effect this filter has on an image.
            </p>
           </td>
          </tr>
          <tr scope="row">
           <td>
            <p>
             Answer question about feature visualization
            </p>
           </td>
           <td>
            <p>
             After visualizing a feature map, answer: what do you think it detects? This answer should be informed by how a filtered image (from the criteria above) looks.
            </p>
           </td>
          </tr>
         </tbody>
        </table>
       </div>
       <div>
        <h2>
         <p>
          Notebook 3: Facial Keypoint Detection
         </p>
        </h2>
        <table class="table table-bordered table-hover">
         <thead>
          <tr class="thead-dark">
           <th>
            Criteria
           </th>
           <th>
            Meet Specification
           </th>
          </tr>
         </thead>
         <tbody>
          <tr scope="row">
           <td>
            <p>
             Detect faces in a given image
            </p>
           </td>
           <td>
            <p>
             Use a Haar cascade face detector to detect faces in a given image.
            </p>
           </td>
          </tr>
          <tr scope="row">
           <td>
            <p>
             Transform each detected face into an input Tensor
            </p>
           </td>
           <td>
            <p>
             You should transform any face into a normalized, square, grayscale image and then a Tensor for your model to take in as input (similar to what the
             <code>
              data_transform
             </code>
             did in Notebook 2).
            </p>
           </td>
          </tr>
          <tr scope="row">
           <td>
            <p>
             Predict and display the keypoints on each face
            </p>
           </td>
           <td>
            <p>
             After face detection with a Haar cascade and face pre-processing, apply your trained model to each detected face, and display the predicted keypoints for each face in the image.
            </p>
           </td>
          </tr>
         </tbody>
        </table>
       </div>
       <div class="jumbotron">
        <h3>
         Tips to make your project standout:
        </h3>
        <p>
         <ul>
          <li>
           Initialize the weights of your CNN by sampling a normal distribution or by performing Xavier initialization so that a particular input signal does not get too big or too small as the network trains.
          </li>
          <li>
           In Notebook 4, create face filters that add sunglasses, mustaches, or any .png of your choice to a given face in the correct location.
          </li>
          <li>
           Use the keypoints around a person's mouth to estimate the curvature of their mouth and create a smile recognition algorithm .
          </li>
          <li>
           Use OpenCV's k-means clustering algorithm to extract the most common facial poses (left, middle, or right-facing, etc.).
          </li>
          <li>
           Use the locations of keypoints on two faces to swap those faces.
          </li>
          <li>
           Add a rotation transform to our list of transformations and use it to do data augmentation.
          </li>
         </ul>
        </p>
       </div>
      </div>
      <div class="col-12">
       <p class="text-right">
       </p>
      </div>
     </div>
    </main>
    <footer class="footer">
     <div class="container">
      <div class="row">
       <div class="col-12">
        <p class="text-center">
         If you need the newest courses Plase add me wechat: udacity6
        </p>
       </div>
      </div>
     </div>
    </footer>
   </div>
  </div>
  <script src="../assets/js/jquery-3.3.1.min.js">
  </script>
  <script src="../assets/js/plyr.polyfilled.min.js">
  </script>
  <script src="../assets/js/bootstrap.min.js">
  </script>
  <script src="../assets/js/jquery.mCustomScrollbar.concat.min.js">
  </script>
  <script src="../assets/js/katex.min.js">
  </script>
  <script>
   // Initialize Plyr video players
    const players = Array.from(document.querySelectorAll('video')).map(p => new Plyr(p));

    // render math equations
    let elMath = document.getElementsByClassName('mathquill');
    for (let i = 0, len = elMath.length; i < len; i += 1) {
      const el = elMath[i];

      katex.render(el.textContent, el, {
        throwOnError: false
      });
    }

    // this hack will make sure Bootstrap tabs work when using Handlebars
    if ($('#question-tabs').length && $('#user-answer-tabs').length) {
      $("#question-tabs a.nav-link").on('click', function () {
        $("#question-tab-contents .tab-pane").hide();
        $($(this).attr("href")).show();
      });
      $("#user-answer-tabs a.nav-link").on('click', function () {
        $("#user-answer-tab-contents .tab-pane").hide();
        $($(this).attr("href")).show();
      });
    } else {
      $("a.nav-link").on('click', function () {
        $(".tab-pane").hide();
        $($(this).attr("href")).show();
      });
    }

    // side bar events
    $(document).ready(function () {
      $("#sidebar").mCustomScrollbar({
        theme: "minimal"
      });

      $('#sidebarCollapse').on('click', function () {
        $('#sidebar, #content').toggleClass('active');
        $('.collapse.in').toggleClass('in');
        $('a[aria-expanded=true]').attr('aria-expanded', 'false');
      });

      // scroll to first video on page loading
      if ($('video').length) {
        $('html,body').animate({ scrollTop: $('div.plyr').prev().offset().top});
      }

      // auto play first video: this may not work with chrome/safari due to autoplay policy
      if (players && players.length > 0) {
        players[0].play();
      }

      // scroll sidebar to current concept
      const currentInSideBar = $( "ul.sidebar-list.components li a:contains('Facial Keypoint Detection')" )
      currentInSideBar.css( "text-decoration", "underline" );
      $("#sidebar").mCustomScrollbar('scrollTo', currentInSideBar);
    });
  </script>
 </body>
</html>
