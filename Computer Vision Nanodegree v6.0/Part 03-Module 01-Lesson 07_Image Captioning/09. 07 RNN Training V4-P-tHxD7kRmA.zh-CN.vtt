WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:04.589
我们仔细研究下解码器是如何用给定图像说明进行训练的

00:00:04.589 --> 00:00:08.269
解码器由 LSTM 单元组成

00:00:08.269 --> 00:00:11.679
它们擅长于记住很长的单词序列

00:00:11.679 --> 00:00:18.015
每个 LSTM 单元要求在每个时间步都看到相同形状的输入向量

00:00:18.015 --> 00:00:23.625
第一个单元与 CNN 编码器的输出特征向量相连

00:00:23.625 --> 00:00:28.600
之前我提到 有一个嵌入层将每个输入单词

00:00:28.600 --> 00:00:34.340
变成特定形状的向量 然后再当做输入馈送到 RNN 中

00:00:34.340 --> 00:00:40.445
我们需要对 CNN 的输出特征向量应用相同的转换

00:00:40.445 --> 00:00:44.869
将此特征向量嵌入为期望的输入形状后

00:00:44.869 --> 00:00:50.169
我们就可以开始 RNN 训练流程了 并将此向量当做第一个输入

00:00:50.170 --> 00:00:53.870
在所有未来时间步 RNN 的输入将是

00:00:53.869 --> 00:00:57.134
训练说明的单个单词

00:00:57.134 --> 00:00:59.199
在训练开始时

00:00:59.200 --> 00:01:01.549
我们有一些来自 CNN 的输入

00:01:01.548 --> 00:01:04.875
和具有初始状态的 LSTM 单元

00:01:04.875 --> 00:01:08.135
RNN 有两项责任

00:01:08.135 --> 00:01:12.830
责任一是记住输入特征向量的空间信息

00:01:12.829 --> 00:01:15.924
责任二是预测下个单词

00:01:15.924 --> 00:01:21.489
我们知道它生成的第一个单词应该始终为起始标记

00:01:21.489 --> 00:01:24.924
下个单词应该是训练说明里的单词

00:01:24.924 --> 00:01:29.229
对于我们的说明“A man holding a slice of pizza.”

00:01:29.230 --> 00:01:33.125
我们知道起始标记之后是 a

00:01:33.125 --> 00:01:37.385
a 之后是 man 以此类推

00:01:37.385 --> 00:01:39.450
在每个时间步

00:01:39.450 --> 00:01:42.115
我们将当前说明单词作为输入

00:01:42.114 --> 00:01:47.689
并将其与 LSTM 单元的隐藏状态相结合 生成输出

00:01:47.689 --> 00:01:52.274
这个输出然后传入全连接层

00:01:52.275 --> 00:01:57.115
生成表示概率最高的下个单词的概率分布

00:01:57.114 --> 00:02:02.274
这是将 softmax 应用到分类任务上的效果

00:02:02.275 --> 00:02:03.605
但在此示例中

00:02:03.605 --> 00:02:08.594
它生成一个下个单词得分列表 而不是类别得分列表

00:02:08.594 --> 00:02:11.579
我们将说明中的下个单词馈送到网络中

00:02:11.579 --> 00:02:15.085
以此类推 直到抵达结束标记

00:02:15.085 --> 00:02:20.465
LSTM 的隐藏状态是上个状态中

00:02:20.465 --> 00:02:21.884
该 LSTM 的输入标记函数

00:02:21.884 --> 00:02:25.174
我将此函数称为递推函数

00:02:25.175 --> 00:02:28.775
递推函数由权重定义

00:02:28.775 --> 00:02:31.890
在训练流程中

00:02:31.889 --> 00:02:35.069
此模型利用反向传播更新这些权重

00:02:35.069 --> 00:02:38.099
直到 LSTM 单元学习根据给定的当前输入单词

00:02:38.099 --> 00:02:42.685
生成正确的下个说明单词

00:02:42.685 --> 00:02:44.634
和大多数模型一样

00:02:44.634 --> 00:02:47.979
你也可以批处理训练数据

00:02:47.979 --> 00:02:53.009
模型在每个训练批次之后会更新权重

00:02:53.009 --> 00:02:55.349
批次大小是在一个训练步中

00:02:55.349 --> 00:02:59.234
发送给网络的图像说明对数量

00:02:59.235 --> 00:03:01.410
模型训练后

00:03:01.409 --> 00:03:04.859
它将从很多图像说明对中学习规律

00:03:04.860 --> 00:03:08.800
应该能够为新的图像数据生成说明

