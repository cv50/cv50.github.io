WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:02.069
图像说明网络的 RNN 组件

00:00:02.069 --> 00:00:06.480
是用 COCO 数据集中的图像说明训练的

00:00:06.480 --> 00:00:09.240
我们的目标是训练 RNN 根据之前的单词

00:00:09.240 --> 00:00:13.120
预测句子的下个单词

00:00:13.119 --> 00:00:16.564
但是如何用字符串数据训练它呢？

00:00:16.565 --> 00:00:19.200
神经网络在字符串上的训练效果不好

00:00:19.199 --> 00:00:22.559
它们需要明确定义的数值输出

00:00:22.559 --> 00:00:27.009
来有效地执行反向传播并学习生成相似的输出

00:00:27.010 --> 00:00:30.270
因此 我们需要将与图像关联的说明

00:00:30.269 --> 00:00:33.839
转换为标记化的单词列表

00:00:33.840 --> 00:00:38.325
这种标记化操作会将任何字符串转换为整数列表

00:00:38.325 --> 00:00:40.685
标记化的原理是什么？

00:00:40.685 --> 00:00:45.390
首先 我们遍历所有训练说明

00:00:45.390 --> 00:00:49.789
并创建一个字典 将所有唯一单词映射到数值索引

00:00:49.789 --> 00:00:52.289
因此 对于我们遇到的每个单词

00:00:52.289 --> 00:00:56.825
都可以在这个字典中找到相应的整数值

00:00:56.825 --> 00:01:01.265
这个字典中的单词称为词汇表

00:01:01.265 --> 00:01:05.745
词汇表通常还包含几个特殊标记

00:01:05.745 --> 00:01:09.920
在此示例中 我们将向字典中添加两个特殊标记

00:01:09.920 --> 00:01:15.594
&lt;start&gt; 和 &lt;end&gt; 标记 表示句子的起始和结束位置

00:01:15.594 --> 00:01:19.954
整个词汇表的长度是训练数据集中的唯一单词数量加上 2

00:01:19.954 --> 00:01:24.579
即起始和结束标记

00:01:24.579 --> 00:01:27.364
我们来看看这个示例说明

00:01:27.364 --> 00:01:31.875
“A person doing a trick while riding a skateboard.”

00:01:31.875 --> 00:01:36.079
此说明被转换成标记列表

00:01:36.079 --> 00:01:41.534
包含特殊的起始和结束标记 表示句子的起始和结尾处

00:01:41.534 --> 00:01:46.329
这个标记列表然后被转换成整数列表

00:01:46.329 --> 00:01:51.810
这些整数来自将词汇表中的独特单词映射到整数值的字典

00:01:51.810 --> 00:01:54.984
在将这些单词作为输入发送给 RNN 之前

00:01:54.984 --> 00:01:58.239
还有一步 也就是嵌入层

00:01:58.239 --> 00:02:03.745
嵌入层将说明中的每个单词转换为一个向量 这些向量具有预期的一致形状

00:02:03.745 --> 00:02:05.510
在此嵌入步骤之后

00:02:05.510 --> 00:02:08.140
我们最终准备好训练 RNN

00:02:08.139 --> 00:02:11.879
它能够预测句子中的下个概率最高的单词

