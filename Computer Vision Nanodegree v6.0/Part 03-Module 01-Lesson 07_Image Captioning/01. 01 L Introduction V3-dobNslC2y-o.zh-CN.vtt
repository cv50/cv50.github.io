WEBVTT
Kind: captions
Language: zh-CN

00:00:03.020 --> 00:00:06.429
我们学习了用于图像分类和对象定位的

00:00:06.429 --> 00:00:09.539
卷积神经网络

00:00:09.539 --> 00:00:14.933
并且学习了主要用于文本生成的循环神经网络

00:00:14.933 --> 00:00:19.268
你了解了 LSTM 等网络如何从

00:00:19.268 --> 00:00:21.504
一系列单词或字符等序列数据中学习规律

00:00:21.504 --> 00:00:24.519
这些网络使用隐藏层逐渐将

00:00:24.519 --> 00:00:27.789
一层的输出与下层的输入相连

00:00:27.789 --> 00:00:30.160
这样就形成了记忆循环

00:00:30.160 --> 00:00:32.814
使网络能够从之前的信息中学习规律

00:00:32.814 --> 00:00:35.949
在此部分 我们将学习如何同时利用这两种网络

00:00:35.950 --> 00:00:38.760
创建一个自动图像说明模型

00:00:38.759 --> 00:00:41.504
该模型会接受一个输入图像

00:00:41.505 --> 00:00:44.825
并输出描述该图像的文本序列

00:00:44.825 --> 00:00:48.190
图像说明用在了各种应用场合

00:00:48.189 --> 00:00:52.349
例如 图像说明可以用来向盲人或视力低下人士描述图像

00:00:52.350 --> 00:00:56.975
这类人士依赖于声音和文本来描述场景

00:00:56.975 --> 00:01:01.380
在网络开发中 一个良好做法是为网页上出现的任何图像提供说明

00:01:01.380 --> 00:01:06.085
使系统可以阅读或朗读图像 而不仅仅是展示图像

00:01:06.084 --> 00:01:08.375
这样使得网络内容具有无障碍功能

00:01:08.375 --> 00:01:12.879
同样 说明可以用来实时描述视频

00:01:12.879 --> 00:01:15.289
你可以想象到很多很有用的

00:01:15.290 --> 00:01:18.455
自动图像生成应用场景

00:01:18.454 --> 00:01:21.739
这节课和接下来的项目将专门讲解

00:01:21.739 --> 00:01:25.494
如何创建为图像生成描述性说明的模型

00:01:25.495 --> 00:01:29.094
为了帮助我们学习图像说明模型的架构

00:01:29.094 --> 00:01:31.849
接下来大家将认识下 Kelvin Lin

00:01:31.849 --> 00:01:36.000
他是在 Nvidia 深度学习研究所任职的一名行业专家.
最新课程跟课件还有一对一辅导请加wx：udacity6

