WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:05.339
你可以通过多种方式将 CNN 的输出与下个 RNN 相连

00:00:05.339 --> 00:00:09.060
但是在所有方式中 从 CNN 中提取的特征向量

00:00:09.060 --> 00:00:12.600
都需要经历一些处理步骤

00:00:12.599 --> 00:00:16.589
才能用作 RNN 第一个单元的输入

00:00:16.589 --> 00:00:20.730
有时候 在将 CNN 输出用作 RNN 的输入之前

00:00:20.730 --> 00:00:27.655
使用额外的全连接层或线性层级解析 CNN 输出很有用

00:00:27.655 --> 00:00:31.810
这与你看到的其他迁移学习示例很相似

00:00:31.809 --> 00:00:34.460
我们使用的 CNN 已经预先经过训练

00:00:34.460 --> 00:00:38.160
在其末尾添加一个未训练过的线性层级使我们能够

00:00:38.159 --> 00:00:43.559
在训练整个模型生成图像说明时 仅调整这个最后层级

00:00:43.560 --> 00:00:48.090
从 CNN 中提取特征向量并处理该向量后

00:00:48.090 --> 00:00:52.770
我们可以使用它作为 RNN 的初始输入

00:00:52.770 --> 00:00:58.210
RNN 的作用是解码处理过的特征向量并将其转换为自然语言

00:00:58.210 --> 00:01:01.698
网络的这部分通常称为解码器

00:01:01.698 --> 00:01:07.090
接下来 我们将深入了解图像生成及如何训练解码器

