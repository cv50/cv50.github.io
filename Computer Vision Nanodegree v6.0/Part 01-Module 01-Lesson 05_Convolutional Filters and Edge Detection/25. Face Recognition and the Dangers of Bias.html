<!-- udacimak v1.4.4 -->
<!DOCTYPE html>
<html lang="en">
 <head>
  <meta charset="utf-8"/>
  <meta content="width=device-width, initial-scale=1.0" name="viewport"/>
  <meta content="ie=edge" http-equiv="X-UA-Compatible"/>
  <title>
   Face Recognition and the Dangers of Bias
  </title>
  <link href="../assets/css/bootstrap.min.css" rel="stylesheet"/>
  <link href="../assets/css/plyr.css" rel="stylesheet"/>
  <link href="../assets/css/katex.min.css" rel="stylesheet"/>
  <link href="../assets/css/jquery.mCustomScrollbar.min.css" rel="stylesheet"/>
  <link href="../assets/css/styles.css" rel="stylesheet"/>
  <link href="../assets/img/udacimak.png" rel="shortcut icon" type="image/png">
  </link>
 </head>
 <body>
  <div class="wrapper">
   <nav id="sidebar">
    <div class="sidebar-header">
     <h3>
      Convolutional Filters and Edge Detection
     </h3>
    </div>
    <ul class="sidebar-list list-unstyled CTAs">
     <li>
      <a class="article" href="../index.html">
       Back to Home
      </a>
     </li>
    </ul>
    <ul class="sidebar-list list-unstyled components">
     <li class="">
      <a href="01. Filters and Finding Edges.html">
       01. Filters and Finding Edges
      </a>
     </li>
     <li class="">
      <a href="02. Frequency in Images.html">
       02. Frequency in Images
      </a>
     </li>
     <li class="">
      <a href="03. Notebook Fourier Transforms.html">
       03. Notebook: Fourier Transforms
      </a>
     </li>
     <li class="">
      <a href="04. Quiz Fourier Tranform Image.html">
       04. Quiz: Fourier Tranform Image
      </a>
     </li>
     <li class="">
      <a href="05. High-pass Filters.html">
       05. High-pass Filters
      </a>
     </li>
     <li class="">
      <a href="06. Quiz Kernels.html">
       06. Quiz: Kernels
      </a>
     </li>
     <li class="">
      <a href="07. Creating a Filter.html">
       07. Creating a Filter
      </a>
     </li>
     <li class="">
      <a href="08. Gradients and Sobel Filters.html">
       08. Gradients and Sobel Filters
      </a>
     </li>
     <li class="">
      <a href="09. Notebook Finding Edges.html">
       09. Notebook: Finding Edges
      </a>
     </li>
     <li class="">
      <a href="10. Low-pass Filters.html">
       10. Low-pass Filters
      </a>
     </li>
     <li class="">
      <a href="11. Gaussian Blur.html">
       11. Gaussian Blur
      </a>
     </li>
     <li class="">
      <a href="12. Notebook Gaussian Blur.html">
       12. Notebook: Gaussian Blur
      </a>
     </li>
     <li class="">
      <a href="13. Notebook Fourier Transforms of Filters.html">
       13. Notebook: Fourier Transforms of Filters
      </a>
     </li>
     <li class="">
      <a href="14. Convolutional Layer.html">
       14. Convolutional Layer
      </a>
     </li>
     <li class="">
      <a href="15. Canny Edge Detector.html">
       15. Canny Edge Detector
      </a>
     </li>
     <li class="">
      <a href="16. Notebook Canny Edge Detection.html">
       16. Notebook: Canny Edge Detection
      </a>
     </li>
     <li class="">
      <a href="17. Shape Detection.html">
       17. Shape Detection
      </a>
     </li>
     <li class="">
      <a href="18. Hough Transform.html">
       18. Hough Transform
      </a>
     </li>
     <li class="">
      <a href="19. Quiz Hough Space.html">
       19. Quiz: Hough Space
      </a>
     </li>
     <li class="">
      <a href="20. Hough Line Detection.html">
       20. Hough Line Detection
      </a>
     </li>
     <li class="">
      <a href="21. Notebook Hough Detections.html">
       21. Notebook: Hough Detections
      </a>
     </li>
     <li class="">
      <a href="22. Object Recognition &amp; Introducing Haar Cascades.html">
       22. Object Recognition &amp; Introducing Haar Cascades
      </a>
     </li>
     <li class="">
      <a href="23. Haar Cascades.html">
       23. Haar Cascades
      </a>
     </li>
     <li class="">
      <a href="24. Notebook Haar Cascade Face Detection.html">
       24. Notebook: Haar Cascade Face Detection
      </a>
     </li>
     <li class="">
      <a href="25. Face Recognition and the Dangers of Bias.html">
       25. Face Recognition and the Dangers of Bias
      </a>
     </li>
     <li class="">
      <a href="26. Beyond Edges, Selecting Different Features.html">
       26. Beyond Edges, Selecting Different Features
      </a>
     </li>
    </ul>
    <ul class="sidebar-list list-unstyled CTAs">
     <li>
      <a class="article" href="../index.html">
       Back to Home
      </a>
     </li>
    </ul>
   </nav>
   <div id="content">
    <header class="container-fluild header">
     <div class="container">
      <div class="row">
       <div class="col-12">
        <div class="align-items-middle">
         <button class="btn btn-toggle-sidebar" id="sidebarCollapse" type="button">
          <div>
          </div>
          <div>
          </div>
          <div>
          </div>
         </button>
         <h1 style="display: inline-block">
          25. Face Recognition and the Dangers of Bias
         </h1>
        </div>
       </div>
      </div>
     </div>
    </header>
    <main class="container">
     <div class="row">
      <div class="col-12">
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <h2 id="algorithms-with-human-and-data-bias">
          Algorithms with Human and Data Bias
         </h2>
         <p>
          Most of the models you've seen and/or programmed, rely on large sets of data to train and learn. When you approach a challenge, it's up to you as a programmer, to define functions and a model for classifying image data. Programmers and data define how classification algorithms like face recognition work.
         </p>
         <p>
          It's important to note that both data and humans come with their own biases, with unevenly distributed image types or personal preferences, respectively. And it's important to note that these biases propagate into the creation of algorithms. If we consider face recognition, think about the case in which a model like a Haar Cascade is trained on faces that are mainly white and female; this network will then excel at detecting those kinds of faces but not others. If this model is meant for general face recognition, then the biased data has ended up creating a biased model, and algorithms that do not reflect the diversity of the users it aims to serve is not very useful at all.
         </p>
         <p>
          The computer scientist,
          <a href="https://www.media.mit.edu/people/joyab/overview/" rel="noopener noreferrer" target="_blank">
           Joy Buolamwini
          </a>
          , based out of the MIT Media Lab, has studied bias in decision-making algorithms, and her work has revealed some of the extent of this problem. One study looked at the error rates of facial recognition programs for women by shades of skin color; results pictured below.
         </p>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <figure class="figure">
          <img alt="Image of facial recognition error rates, taken from MIT Media Lab's [gender shades website](http://gendershades.org/index.html)." class="img img-fluid" src="img/screen-shot-2018-04-23-at-11.34.35-pm.png"/>
          <figcaption class="figure-caption">
           <p>
            Image of facial recognition error rates, taken from MIT Media Lab's
            <a href="http://gendershades.org/index.html" rel="noopener noreferrer" target="_blank">
             gender shades website
            </a>
            .
           </p>
          </figcaption>
         </figure>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <h2 id="analyzing-fairness">
          Analyzing Fairness
         </h2>
         <p>
          Identifying the fairness of a given algorithm is an active area of research. Here is an example of using a GAN (Generative Adversarial Network) to help a classifier detect bias and correct it's predictions:
          <a href="https://blog.godatadriven.com/fairness-in-pytorch" rel="noopener noreferrer" target="_blank">
           Implementing a fair classifier in PyTorch.
          </a>
          And another paper that shows how "fair"
          <a href="http://bair.berkeley.edu/blog/2018/05/17/delayed-impact/" rel="noopener noreferrer" target="_blank">
           credit loans affect diff populations
          </a>
          (with helpful, interactive plots). I think that as computer vision becomes more ubiquitous, this area of research will become more and more important, and it is worth reading about and educating yourself!
         </p>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <figure class="figure">
          <img alt="From credit loan paper, Delayed Impact of Fair Machine Learning." class="img img-fluid" src="img/screen-shot-2018-06-21-at-1.39.47-pm.png"/>
          <figcaption class="figure-caption">
           <p>
            From credit loan paper, Delayed Impact of Fair Machine Learning.
           </p>
          </figcaption>
         </figure>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <h2 id="working-to-eliminate-bias">
          Working to Eliminate Bias
         </h2>
         <p>
          Biased results are the effect of bias in programmers and in data, and we can work to change this. We must be critical of our own work, critical of what we read, and develop methods for testing such algorithms. As you learn more about AI and deep learning models, you'll learn some methods for visualizing what a neural network has learned, and you're encouraged to look at your data and make sure that it is balanced; data is the foundation for any machine and deep learning model. It's also good practice to test any algorithm for bias; as you develop deep learning models, it's a good idea to test how they respond to a variety of challenges and see if they have any weaknesses.
         </p>
         <p>
          If you'd like to learn about eliminating bias in AI, check out this
          <a href="https://hbr.org/2018/02/can-we-keep-our-biases-from-creeping-into-ai?utm_campaign=hbr&amp;utm_source=twitter&amp;utm_medium=social" rel="noopener noreferrer" target="_blank">
           Harvard Business Review article
          </a>
          . I'd also recommend listening to Joy Buolamwini's
          <a href="https://www.ted.com/talks/joy_buolamwini_how_i_m_fighting_bias_in_algorithms" rel="noopener noreferrer" target="_blank">
           TED talk
          </a>
          and reading the original Gender Shades paper.
         </p>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <h4 id="further-reading">
          Further Reading
         </h4>
         <p>
          If you are really curious about bias in algorithms, there are also some excellent books on ethics in software engineering:
         </p>
         <ul>
          <li>
           Weapons of Math Destruction, Cathy O'Neil
          </li>
          <li>
           Algorithms of Oppression, Safiya Umoja Noble
          </li>
          <li>
           Automating Inequality, Virginia Eubanks
          </li>
          <li>
           Technically Wrong, Sara Wachter-Boettchera
          </li>
         </ul>
        </div>
       </div>
       <div class="divider">
       </div>
      </div>
      <div class="col-12">
       <p class="text-right">
        <a class="btn btn-outline-primary mt-4" href="26. Beyond Edges, Selecting Different Features.html" role="button">
         Next Concept
        </a>
       </p>
      </div>
     </div>
    </main>
    <footer class="footer">
     <div class="container">
      <div class="row">
       <div class="col-12">
        <p class="text-center">
         If you need the newest courses Plase add me wechat: udacity6
        </p>
       </div>
      </div>
     </div>
    </footer>
   </div>
  </div>
  <script src="../assets/js/jquery-3.3.1.min.js">
  </script>
  <script src="../assets/js/plyr.polyfilled.min.js">
  </script>
  <script src="../assets/js/bootstrap.min.js">
  </script>
  <script src="../assets/js/jquery.mCustomScrollbar.concat.min.js">
  </script>
  <script src="../assets/js/katex.min.js">
  </script>
  <script>
   // Initialize Plyr video players
    const players = Array.from(document.querySelectorAll('video')).map(p => new Plyr(p));

    // render math equations
    let elMath = document.getElementsByClassName('mathquill');
    for (let i = 0, len = elMath.length; i < len; i += 1) {
      const el = elMath[i];

      katex.render(el.textContent, el, {
        throwOnError: false
      });
    }

    // this hack will make sure Bootstrap tabs work when using Handlebars
    if ($('#question-tabs').length && $('#user-answer-tabs').length) {
      $("#question-tabs a.nav-link").on('click', function () {
        $("#question-tab-contents .tab-pane").hide();
        $($(this).attr("href")).show();
      });
      $("#user-answer-tabs a.nav-link").on('click', function () {
        $("#user-answer-tab-contents .tab-pane").hide();
        $($(this).attr("href")).show();
      });
    } else {
      $("a.nav-link").on('click', function () {
        $(".tab-pane").hide();
        $($(this).attr("href")).show();
      });
    }

    // side bar events
    $(document).ready(function () {
      $("#sidebar").mCustomScrollbar({
        theme: "minimal"
      });

      $('#sidebarCollapse').on('click', function () {
        $('#sidebar, #content').toggleClass('active');
        $('.collapse.in').toggleClass('in');
        $('a[aria-expanded=true]').attr('aria-expanded', 'false');
      });

      // scroll to first video on page loading
      if ($('video').length) {
        $('html,body').animate({ scrollTop: $('div.plyr').prev().offset().top});
      }

      // auto play first video: this may not work with chrome/safari due to autoplay policy
      if (players && players.length > 0) {
        players[0].play();
      }

      // scroll sidebar to current concept
      const currentInSideBar = $( "ul.sidebar-list.components li a:contains('25. Face Recognition and the Dangers of Bias')" )
      currentInSideBar.css( "text-decoration", "underline" );
      $("#sidebar").mCustomScrollbar('scrollTo', currentInSideBar);
    });
  </script>
 </body>
</html>
