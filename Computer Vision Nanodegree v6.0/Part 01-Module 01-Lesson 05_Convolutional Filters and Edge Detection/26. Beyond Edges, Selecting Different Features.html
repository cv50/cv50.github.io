<!-- udacimak v1.4.4 -->
<!DOCTYPE html>
<html lang="en">
 <head>
  <meta charset="utf-8"/>
  <meta content="width=device-width, initial-scale=1.0" name="viewport"/>
  <meta content="ie=edge" http-equiv="X-UA-Compatible"/>
  <title>
   Beyond Edges, Selecting Different Features
  </title>
  <link href="../assets/css/bootstrap.min.css" rel="stylesheet"/>
  <link href="../assets/css/plyr.css" rel="stylesheet"/>
  <link href="../assets/css/katex.min.css" rel="stylesheet"/>
  <link href="../assets/css/jquery.mCustomScrollbar.min.css" rel="stylesheet"/>
  <link href="../assets/css/styles.css" rel="stylesheet"/>
  <link href="../assets/img/udacimak.png" rel="shortcut icon" type="image/png">
  </link>
 </head>
 <body>
  <div class="wrapper">
   <nav id="sidebar">
    <div class="sidebar-header">
     <h3>
      Convolutional Filters and Edge Detection
     </h3>
    </div>
    <ul class="sidebar-list list-unstyled CTAs">
     <li>
      <a class="article" href="../index.html">
       Back to Home
      </a>
     </li>
    </ul>
    <ul class="sidebar-list list-unstyled components">
     <li class="">
      <a href="01. Filters and Finding Edges.html">
       01. Filters and Finding Edges
      </a>
     </li>
     <li class="">
      <a href="02. Frequency in Images.html">
       02. Frequency in Images
      </a>
     </li>
     <li class="">
      <a href="03. Notebook Fourier Transforms.html">
       03. Notebook: Fourier Transforms
      </a>
     </li>
     <li class="">
      <a href="04. Quiz Fourier Tranform Image.html">
       04. Quiz: Fourier Tranform Image
      </a>
     </li>
     <li class="">
      <a href="05. High-pass Filters.html">
       05. High-pass Filters
      </a>
     </li>
     <li class="">
      <a href="06. Quiz Kernels.html">
       06. Quiz: Kernels
      </a>
     </li>
     <li class="">
      <a href="07. Creating a Filter.html">
       07. Creating a Filter
      </a>
     </li>
     <li class="">
      <a href="08. Gradients and Sobel Filters.html">
       08. Gradients and Sobel Filters
      </a>
     </li>
     <li class="">
      <a href="09. Notebook Finding Edges.html">
       09. Notebook: Finding Edges
      </a>
     </li>
     <li class="">
      <a href="10. Low-pass Filters.html">
       10. Low-pass Filters
      </a>
     </li>
     <li class="">
      <a href="11. Gaussian Blur.html">
       11. Gaussian Blur
      </a>
     </li>
     <li class="">
      <a href="12. Notebook Gaussian Blur.html">
       12. Notebook: Gaussian Blur
      </a>
     </li>
     <li class="">
      <a href="13. Notebook Fourier Transforms of Filters.html">
       13. Notebook: Fourier Transforms of Filters
      </a>
     </li>
     <li class="">
      <a href="14. Convolutional Layer.html">
       14. Convolutional Layer
      </a>
     </li>
     <li class="">
      <a href="15. Canny Edge Detector.html">
       15. Canny Edge Detector
      </a>
     </li>
     <li class="">
      <a href="16. Notebook Canny Edge Detection.html">
       16. Notebook: Canny Edge Detection
      </a>
     </li>
     <li class="">
      <a href="17. Shape Detection.html">
       17. Shape Detection
      </a>
     </li>
     <li class="">
      <a href="18. Hough Transform.html">
       18. Hough Transform
      </a>
     </li>
     <li class="">
      <a href="19. Quiz Hough Space.html">
       19. Quiz: Hough Space
      </a>
     </li>
     <li class="">
      <a href="20. Hough Line Detection.html">
       20. Hough Line Detection
      </a>
     </li>
     <li class="">
      <a href="21. Notebook Hough Detections.html">
       21. Notebook: Hough Detections
      </a>
     </li>
     <li class="">
      <a href="22. Object Recognition &amp; Introducing Haar Cascades.html">
       22. Object Recognition &amp; Introducing Haar Cascades
      </a>
     </li>
     <li class="">
      <a href="23. Haar Cascades.html">
       23. Haar Cascades
      </a>
     </li>
     <li class="">
      <a href="24. Notebook Haar Cascade Face Detection.html">
       24. Notebook: Haar Cascade Face Detection
      </a>
     </li>
     <li class="">
      <a href="25. Face Recognition and the Dangers of Bias.html">
       25. Face Recognition and the Dangers of Bias
      </a>
     </li>
     <li class="">
      <a href="26. Beyond Edges, Selecting Different Features.html">
       26. Beyond Edges, Selecting Different Features
      </a>
     </li>
    </ul>
    <ul class="sidebar-list list-unstyled CTAs">
     <li>
      <a class="article" href="../index.html">
       Back to Home
      </a>
     </li>
    </ul>
   </nav>
   <div id="content">
    <header class="container-fluild header">
     <div class="container">
      <div class="row">
       <div class="col-12">
        <div class="align-items-middle">
         <button class="btn btn-toggle-sidebar" id="sidebarCollapse" type="button">
          <div>
          </div>
          <div>
          </div>
          <div>
          </div>
         </button>
         <h1 style="display: inline-block">
          26. Beyond Edges, Selecting Different Features
         </h1>
        </div>
       </div>
      </div>
     </div>
    </header>
    <main class="container">
     <div class="row">
      <div class="col-12">
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <h1 id="features">
          Features
         </h1>
         <p>
          Features and feature extraction is the basis for many computer vision applications. The idea is that any set of data, such as a set of images, can be represented by a smaller, simpler model made of a combination of visual features: a few colors and shapes. (This is true with one exception: completely random data!)
         </p>
         <p>
          If you can find a good model for any set of data, then you can start to find ways to identify patterns in data based on similarities and differences in the features in an image. This is especially important when we get to deep learning models for image classification, which you'll see soon.
         </p>
         <p>
          Below is an example of a simple model for rainbow colors. Each of the colors below is actually a combination of a smaller set of color features: red, yellow, and blue. For example, purple = red + blue. And these simple features give us a way to represent a variety of colors and classify them accoring to their red, yellow, and blue components!
         </p>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <figure class="figure">
          <img alt="Color classification model." class="img img-fluid" src="img/screen-shot-2018-05-31-at-3.31.32-pm.png"/>
          <figcaption class="figure-caption">
           <p>
            Color classification model.
           </p>
          </figcaption>
         </figure>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <h2 id="types-of-features">
          Types of Features
         </h2>
         <p>
          We've described features as measurable pieces of data in an image that help distinguish between different classes of images.
         </p>
         <p>
          There are two main types of features:
         </p>
         <ol>
          <li>
           Color-based and
          </li>
          <li>
           Shape-based
          </li>
         </ol>
         <p>
          Both of these are useful in different cases and they are often powerful together. We know that color is all you need should you want to classify day/night images or implement a green screen. Let's look at another example: say I wanted to classify a stop sign vs. any other traffic sign. Stop signs are
          <em>
           supposed
          </em>
          to stand out in color and shape! A stop sign is an octagon (it has 8 flat sides) and it is very red. It's red color is often enough to distinguish it, but the sign can be obscured by trees or other artifacts and the shape ends up being important, too.
         </p>
         <p>
          As a different example, say I want to detect a face and perform facial recognition. I'll first want to detect a face in a given image; this means at least recognizing the boundaries and some features on that face, which are all determined by shape. Specifically, I'll want to identify the edges of the face and the eyes and mouth on that face, so that I can identify the face and recognize it. Color is not very useful in this case, but shape is critical.
         </p>
         <h3 id="a-note-on-shape">
          A note on shape
         </h3>
         <p>
          Edges are one of the simplest shapes that you can detect; edges often define the boundaries between objects but they may not provide enough information to find and identify small features on those objects (such as eyes on a face) and in the next videos, we'll look at methods for finding even more complex shapes.
         </p>
         <p>
          As you continue learning, keep in mind that selecting the right feature is an important computer vision task.
         </p>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <h2 id="example-application-lane-finding">
          Example Application: Lane Finding
         </h2>
         <p>
          You've already had some practice with this concept, but you can use feature/edge detection and color transforms to very effectively detect lane lines on a road. If you'd like to learn more about this technique, I suggest checking out
          <a href="https://towardsdatascience.com/teaching-cars-to-see-advanced-lane-detection-using-computer-vision-87a01de0424f" rel="noopener noreferrer" target="_blank">
           this blog post
          </a>
          .
         </p>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <figure class="figure">
          <img alt="Identifying edges and lane markings on a road." class="img img-fluid" src="img/screen-shot-2018-05-31-at-3.21.06-pm.png"/>
          <figcaption class="figure-caption">
           <p>
            Identifying edges and lane markings on a road.
           </p>
          </figcaption>
         </figure>
        </div>
       </div>
       <div class="divider">
       </div>
      </div>
      <div class="col-12">
       <p class="text-right">
       </p>
      </div>
     </div>
    </main>
    <footer class="footer">
     <div class="container">
      <div class="row">
       <div class="col-12">
        <p class="text-center">
         If you need the newest courses Plase add me wechat: udacity6
        </p>
       </div>
      </div>
     </div>
    </footer>
   </div>
  </div>
  <script src="../assets/js/jquery-3.3.1.min.js">
  </script>
  <script src="../assets/js/plyr.polyfilled.min.js">
  </script>
  <script src="../assets/js/bootstrap.min.js">
  </script>
  <script src="../assets/js/jquery.mCustomScrollbar.concat.min.js">
  </script>
  <script src="../assets/js/katex.min.js">
  </script>
  <script>
   // Initialize Plyr video players
    const players = Array.from(document.querySelectorAll('video')).map(p => new Plyr(p));

    // render math equations
    let elMath = document.getElementsByClassName('mathquill');
    for (let i = 0, len = elMath.length; i < len; i += 1) {
      const el = elMath[i];

      katex.render(el.textContent, el, {
        throwOnError: false
      });
    }

    // this hack will make sure Bootstrap tabs work when using Handlebars
    if ($('#question-tabs').length && $('#user-answer-tabs').length) {
      $("#question-tabs a.nav-link").on('click', function () {
        $("#question-tab-contents .tab-pane").hide();
        $($(this).attr("href")).show();
      });
      $("#user-answer-tabs a.nav-link").on('click', function () {
        $("#user-answer-tab-contents .tab-pane").hide();
        $($(this).attr("href")).show();
      });
    } else {
      $("a.nav-link").on('click', function () {
        $(".tab-pane").hide();
        $($(this).attr("href")).show();
      });
    }

    // side bar events
    $(document).ready(function () {
      $("#sidebar").mCustomScrollbar({
        theme: "minimal"
      });

      $('#sidebarCollapse').on('click', function () {
        $('#sidebar, #content').toggleClass('active');
        $('.collapse.in').toggleClass('in');
        $('a[aria-expanded=true]').attr('aria-expanded', 'false');
      });

      // scroll to first video on page loading
      if ($('video').length) {
        $('html,body').animate({ scrollTop: $('div.plyr').prev().offset().top});
      }

      // auto play first video: this may not work with chrome/safari due to autoplay policy
      if (players && players.length > 0) {
        players[0].play();
      }

      // scroll sidebar to current concept
      const currentInSideBar = $( "ul.sidebar-list.components li a:contains('26. Beyond Edges, Selecting Different Features')" )
      currentInSideBar.css( "text-decoration", "underline" );
      $("#sidebar").mCustomScrollbar('scrollTo', currentInSideBar);
    });
  </script>
 </body>
</html>
