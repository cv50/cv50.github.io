WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:02.730
你已经知道如何定位图像中的一个对象

00:00:02.730 --> 00:00:06.140
即在该对象周围生成一个边界框

00:00:06.139 --> 00:00:08.719
但是如果图像中有多个对象呢？

00:00:08.720 --> 00:00:11.610
如何训练网络检测所有这些对象？

00:00:11.609 --> 00:00:15.824
我们来看看图像中只有两个对象的情形

00:00:15.824 --> 00:00:18.744
如何定位并标记这两个对象？

00:00:18.745 --> 00:00:20.984
一种方法是尝试简化该输入图像

00:00:20.984 --> 00:00:24.429
并将其拆分为两个不同的区域

00:00:24.429 --> 00:00:27.089
每个区域仅包含一个对象

00:00:27.089 --> 00:00:29.789
然后可以像之前一样继续操作

00:00:29.789 --> 00:00:34.929
将每个区域放入 CNN 中 生成一个类别标签和一个边界框

00:00:34.929 --> 00:00:40.185
你可能会疑问 如果图像中有三个或四个或更多个对象呢？

00:00:40.185 --> 00:00:43.820
真正的挑战是输出不定

00:00:43.820 --> 00:00:48.299
你提前不知道给定图像中有多少个对象

00:00:48.299 --> 00:00:53.009
CNN 和大部分神经网络的输出大小都是固定不变的

00:00:53.009 --> 00:00:57.030
因此 要检测任何图像中数量变化不定的对象

00:00:57.030 --> 00:01:00.780
首先必须将该图像拆分为更小的区域

00:01:00.780 --> 00:01:05.605
一次为一个区域和一个对象生成边界框和类别标签

00:01:05.605 --> 00:01:09.060
稍后我们将学习查找这些区域的技巧

00:01:09.060 --> 00:01:11.680
然后 你将能够定位并分类

00:01:11.680 --> 00:01:14.410
原始图像中出现的任何对象

00:01:14.409 --> 00:01:16.789
无论是 1 个对象还是 3 个或 20 个

00:01:16.790 --> 00:01:20.765
如何将图像拆分为小的区域？

00:01:20.765 --> 00:01:24.099
我们知道我们希望这些区域对应于图像中的不同对象

00:01:24.099 --> 00:01:27.379
并且不希望忽略任何对象

00:01:27.379 --> 00:01:31.030
我们可以创建一系列裁剪区域 确保不会忽略任何对象

00:01:31.030 --> 00:01:34.810
也就是定义一个小的滑动窗口

00:01:34.810 --> 00:01:37.659
并使用某个步长值在整个图像上滑动

00:01:37.659 --> 00:01:41.189
从而在原始输入图像上创建不同的迷你裁剪区域

00:01:41.189 --> 00:01:42.780
然后将每个裁剪区域

00:01:42.780 --> 00:01:45.930
传入 CNN 中并进行分类

00:01:45.930 --> 00:01:48.930
但是 这种方法会生成大量裁剪图像

00:01:48.930 --> 00:01:52.070
并且非常耗时

00:01:52.069 --> 00:01:53.534
在这种情况下

00:01:53.534 --> 00:01:56.359
大部分裁剪的图像甚至不包含对象

00:01:56.359 --> 00:01:59.709
因此 如何更好地选择这些裁剪区域呢？

00:01:59.709 --> 00:02:02.539
尤其是当对象的尺寸和位置变化不一时

00:02:02.540 --> 00:02:07.094
下面 请思考如何改善这个区域选择流程

00:02:07.094 --> 00:02:10.229
你需要确保不会忽略任何对象

00:02:10.229 --> 00:02:13.399
并且不会将大量裁剪区域传入 CNN 中

