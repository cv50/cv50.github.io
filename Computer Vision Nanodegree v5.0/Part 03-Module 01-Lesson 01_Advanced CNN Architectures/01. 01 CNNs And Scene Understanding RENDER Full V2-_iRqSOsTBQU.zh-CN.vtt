WEBVTT
Kind: captions
Language: zh-CN

00:00:05.509 --> 00:00:08.460
到目前为止 你已经见过各种图像处理技巧

00:00:08.460 --> 00:00:13.339
这些技巧在模式识别任务中扮演着重要的角色

00:00:13.339 --> 00:00:15.269
例如图像分类任务

00:00:15.269 --> 00:00:17.199
并且你已经知道卷积神经网络

00:00:17.199 --> 00:00:20.744
如何按照一系列步骤分类图像

00:00:20.745 --> 00:00:24.460
总结下 CNN 首先获取输入图像

00:00:24.460 --> 00:00:27.990
然后将该图像传入多个卷积层和池化层

00:00:27.989 --> 00:00:32.619
生成一组比原始图像尺寸小的特征图

00:00:32.619 --> 00:00:34.539
通过训练流程 这些特征图学会

00:00:34.539 --> 00:00:37.634
提取关于原始图像内容的信息

00:00:37.634 --> 00:00:39.679
然后扁平化这些特征图

00:00:39.679 --> 00:00:42.579
创建一个向量并传递给一系列全连接线性层级

00:00:42.579 --> 00:00:48.009
生成类别得分概率分布

00:00:48.009 --> 00:00:51.964
然后我们可以提取输入图像的预测类别

00:00:51.965 --> 00:00:56.780
简而言之 输入图像并生成预测类别标签

00:00:56.780 --> 00:00:59.075
在这样的分类任务中

00:00:59.075 --> 00:01:03.955
每个图像通常有一个对象需要网络去分类

00:01:03.954 --> 00:01:08.629
但在现实中 通常遇到的是复杂得多的场景

00:01:08.629 --> 00:01:10.994
其中包含很多重叠的对象

00:01:10.995 --> 00:01:14.329
我们可以同时查看和分类多个对象

00:01:14.329 --> 00:01:17.954
甚至可以估计场景中对象之间的距离等

00:01:17.954 --> 00:01:20.090
在这节课 我们将了解不同的 CNN 架构

00:01:20.090 --> 00:01:23.745
并看看它们是如何演变的

00:01:23.745 --> 00:01:27.969
具体而言 我们将学习从场景中检测多个对象的模型

00:01:27.969 --> 00:01:30.359
例如 Faster R-CNN 和 YOLO

00:01:30.359 --> 00:01:32.885
这两种网络查看图像后

00:01:32.885 --> 00:01:34.630
能够将其拆分为更小的区域

00:01:34.629 --> 00:01:37.099
并对每个区域分配一个类别标签

00:01:37.099 --> 00:01:41.494
从而能够发现并标记给定图像中的多个对象

00:01:41.495 --> 00:01:43.040
在这门课程的后续阶段

00:01:43.040 --> 00:01:45.859
你还将学习回归神经网络

00:01:45.859 --> 00:01:48.890
这种网络使你能够处理和生成数据序列

00:01:48.890 --> 00:01:52.430
例如图像帧序列或单词序列

00:01:52.430 --> 00:01:54.290
对于描述视觉场景来说很有用

00:01:54.290 --> 00:01:57.795
例如自动图像说明

00:01:57.795 --> 00:02:02.969
我们先来看看一些可以应用 CNN 的复杂任务

