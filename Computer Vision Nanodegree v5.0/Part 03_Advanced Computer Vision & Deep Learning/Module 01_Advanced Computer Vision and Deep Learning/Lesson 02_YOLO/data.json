{
  "data": {
    "lesson": {
      "id": 521347,
      "key": "5a00ef90-53d9-4a9b-97cd-41ad778af664",
      "title": "YOLO",
      "semantic_type": "Lesson",
      "is_public": true,
      "version": "1.0.0",
      "locale": "en-us",
      "summary": "Learn about the YOLO (You Only Look Once) multi-object detection model and work with a YOLO implementation.",
      "lesson_type": "Classroom",
      "display_workspace_project_only": null,
      "resources": {
        "files": [
          {
            "name": "Videos Zip File",
            "uri": "https://zips.udacity-data.com/5a00ef90-53d9-4a9b-97cd-41ad778af664/521347/1544453057251/YOLO+Videos.zip"
          },
          {
            "name": "Transcripts Zip File",
            "uri": "https://zips.udacity-data.com/5a00ef90-53d9-4a9b-97cd-41ad778af664/521347/1544453053263/YOLO+Subtitles.zip"
          }
        ],
        "google_plus_link": null,
        "career_resource_center_link": null,
        "coaching_appointments_link": null,
        "office_hours_link": null,
        "aws_provisioning_link": null
      },
      "project": null,
      "lab": null,
      "concepts": [
        {
          "id": 521348,
          "key": "8df3c43d-73c0-4a4e-bbdb-73e3ed4fdb3f",
          "title": "Introduction to YOLO",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "8df3c43d-73c0-4a4e-bbdb-73e3ed4fdb3f",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 626098,
              "key": "fb63d613-9d84-4f26-a817-fb88cb973e06",
              "title": "01 Introduction V3",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "uyefSrHZesY",
                "china_cdn_id": "uyefSrHZesY.mp4"
              }
            }
          ]
        },
        {
          "id": 621543,
          "key": "825eebc5-8228-44ab-9281-8e0f40ab5da1",
          "title": "YOLO Output",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "825eebc5-8228-44ab-9281-8e0f40ab5da1",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 626099,
              "key": "58880b67-0a55-4f56-b208-c5c621936454",
              "title": "02 YOLO Output V2",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "MyOuuwk0qC4",
                "china_cdn_id": "MyOuuwk0qC4.mp4"
              }
            }
          ]
        },
        {
          "id": 621544,
          "key": "14030932-f0b9-4378-8473-7c4e599b31ec",
          "title": "Sliding Windows, Revisited",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "14030932-f0b9-4378-8473-7c4e599b31ec",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 626100,
              "key": "5d1a4942-6844-4014-bc9a-c10cb214cebd",
              "title": "03 A Convolutional Approach To Sliding Windows V3",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "8qYqqibIz90",
                "china_cdn_id": "8qYqqibIz90.mp4"
              }
            }
          ]
        },
        {
          "id": 624512,
          "key": "333755d0-67a0-48c1-b42e-964500ad01b9",
          "title": "CNN & Sliding Windows ",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "333755d0-67a0-48c1-b42e-964500ad01b9",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 624563,
              "key": "5cfcaa85-98c9-4d34-844b-76068f355d1c",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "### A Convolutional Approach to Sliding Windows\n\nLet’s assume we have a 16 x 16 x 3 image, like the one shown below. This means the image has a size of 16 by 16 pixels and has 3 channels, corresponding to RGB.",
              "instructor_notes": ""
            },
            {
              "id": 624513,
              "key": "06b34c49-33d6-40bf-b57b-8b308fd28cc3",
              "title": null,
              "semantic_type": "ImageAtom",
              "is_public": true,
              "url": "https://video.udacity-data.com/topher/2018/May/5aef7ae3_diapositiva1/diapositiva1.png",
              "non_google_url": "https://s3.cn-north-1.amazonaws.com.cn/u-img/06b34c49-33d6-40bf-b57b-8b308fd28cc3",
              "caption": "",
              "alt": "",
              "width": 1280,
              "height": 720,
              "instructor_notes": null
            },
            {
              "id": 624514,
              "key": "de953cdd-9b4a-47de-9210-bfcfb0d410e5",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "Let’s now select a window size of 10 x 10 pixels as shown below:",
              "instructor_notes": ""
            },
            {
              "id": 624515,
              "key": "d0499c9b-73d5-4906-b7b4-b767f55d5f08",
              "title": null,
              "semantic_type": "ImageAtom",
              "is_public": true,
              "url": "https://video.udacity-data.com/topher/2018/May/5aef7b30_diapositiva2/diapositiva2.png",
              "non_google_url": "https://s3.cn-north-1.amazonaws.com.cn/u-img/d0499c9b-73d5-4906-b7b4-b767f55d5f08",
              "caption": "",
              "alt": "",
              "width": 1280,
              "height": 720,
              "instructor_notes": null
            },
            {
              "id": 624516,
              "key": "39b45dd5-6dda-44ca-a10c-609938f33eb9",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "If we use a stride of 2 pixels, it will take 16 windows to cover the entire image, as we can see below. \n",
              "instructor_notes": ""
            },
            {
              "id": 624517,
              "key": "2fa811c4-a572-4d24-8ab2-e95ad817e531",
              "title": null,
              "semantic_type": "ImageAtom",
              "is_public": true,
              "url": "https://video.udacity-data.com/topher/2018/May/5aef7bc0_diapositiva3/diapositiva3.png",
              "non_google_url": "https://s3.cn-north-1.amazonaws.com.cn/u-img/2fa811c4-a572-4d24-8ab2-e95ad817e531",
              "caption": "",
              "alt": "",
              "width": 1280,
              "height": 720,
              "instructor_notes": null
            },
            {
              "id": 624518,
              "key": "e274cf91-96fa-4abb-8627-1a389be8bd99",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "In the original Sliding Windows approach, each of these 16 windows will have to be passed individually through a CNN. Let’s assume that CNN has the following architecture:",
              "instructor_notes": ""
            },
            {
              "id": 624565,
              "key": "b32c9918-9ef5-4d4e-a249-0070d63d67f7",
              "title": null,
              "semantic_type": "ImageAtom",
              "is_public": true,
              "url": "https://video.udacity-data.com/topher/2018/May/5aefb1ef_diapositiva4/diapositiva4.jpg",
              "non_google_url": "https://s3.cn-north-1.amazonaws.com.cn/u-img/b32c9918-9ef5-4d4e-a249-0070d63d67f7",
              "caption": "",
              "alt": "",
              "width": 1280,
              "height": 431,
              "instructor_notes": null
            },
            {
              "id": 624520,
              "key": "df3fa182-53e7-4f3e-b201-b1a022b9d910",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "The CNN takes as input a 10 x 10 x 3 image, then it applies 5, 7 x 7 x 3 filters, then it uses a 2 x 2 Max pooling layer, then is has 128, 2 x 2 x 5 filters, then is has 128, 1 x 1 x 128 filters, and finally it has  8, 1 x 1 x 128 filters that represents a softmax output.\n\nWhat will happen if we change the input of the above CNN from 10 x 10 x 3, to 16 x 16 x 3? The result is shown below:",
              "instructor_notes": ""
            },
            {
              "id": 624566,
              "key": "1d4ef13d-0f93-4969-a89a-b3a746b28ebb",
              "title": null,
              "semantic_type": "ImageAtom",
              "is_public": true,
              "url": "https://video.udacity-data.com/topher/2018/May/5aefb270_diapositiva5-1/diapositiva5-1.png",
              "non_google_url": "https://s3.cn-north-1.amazonaws.com.cn/u-img/1d4ef13d-0f93-4969-a89a-b3a746b28ebb",
              "caption": "",
              "alt": "",
              "width": 1280,
              "height": 446,
              "instructor_notes": null
            },
            {
              "id": 624522,
              "key": "5418780c-51ab-4c5c-bf86-10692f1fe400",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "As we can see, this CNN architecture is the same as the one shown before except that it takes as input a 16 x 16 x 3 image. The sizes of each layer change because the input image is larger, but the same filters as before have been applied. \n\nIf we follow the region of the image that corresponds to the first window through this new CNN, we see that the result is the upper-left corner of the last layer (*see image above*). Similarly, if we follow the section of the image that corresponds to the second window through this new CNN, we see the corresponding result in the last layer:\n",
              "instructor_notes": ""
            },
            {
              "id": 624568,
              "key": "d1866ff2-ffce-4516-a0e4-75e390a5efc7",
              "title": null,
              "semantic_type": "ImageAtom",
              "is_public": true,
              "url": "https://video.udacity-data.com/topher/2018/May/5aefb2c0_diapositiva6-1/diapositiva6-1.png",
              "non_google_url": "https://s3.cn-north-1.amazonaws.com.cn/u-img/d1866ff2-ffce-4516-a0e4-75e390a5efc7",
              "caption": "",
              "alt": "",
              "width": 1280,
              "height": 453,
              "instructor_notes": null
            },
            {
              "id": 624525,
              "key": "94d3bdb9-0560-4ee4-abef-e6f4156b4258",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "Likewise, if we follow the section of the image that corresponds to the third window through this new CNN, we see the corresponding result in the last layer, as shown in the image below:",
              "instructor_notes": ""
            },
            {
              "id": 624570,
              "key": "abb0c68a-aaed-4c1f-b0cf-3504003e413c",
              "title": null,
              "semantic_type": "ImageAtom",
              "is_public": true,
              "url": "https://video.udacity-data.com/topher/2018/May/5aefb2fb_diapositiva7-1/diapositiva7-1.png",
              "non_google_url": "https://s3.cn-north-1.amazonaws.com.cn/u-img/abb0c68a-aaed-4c1f-b0cf-3504003e413c",
              "caption": "",
              "alt": "",
              "width": 1280,
              "height": 439,
              "instructor_notes": null
            },
            {
              "id": 624527,
              "key": "eddedfa6-e3af-46a5-b86a-6be373d0b027",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "Finally, if we follow the section of the image that corresponds to the fourth window through this new CNN, we see the corresponding result in the last layer, as shown in the image below:\n",
              "instructor_notes": ""
            },
            {
              "id": 624571,
              "key": "7e06b41c-1e11-48c1-8ec6-c3a0c7bc7a26",
              "title": null,
              "semantic_type": "ImageAtom",
              "is_public": true,
              "url": "https://video.udacity-data.com/topher/2018/May/5aefb335_diapositiva8-1/diapositiva8-1.png",
              "non_google_url": "https://s3.cn-north-1.amazonaws.com.cn/u-img/7e06b41c-1e11-48c1-8ec6-c3a0c7bc7a26",
              "caption": "",
              "alt": "",
              "width": 1280,
              "height": 451,
              "instructor_notes": null
            },
            {
              "id": 624528,
              "key": "7f451e6e-003f-4ce5-a5aa-d536f9a87706",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "In fact, if we follow all the windows through the CNN we see that all the 16 windows are contained within the last layer of this new CNN. Therefore, passing the 16 windows individually through the old CNN is exactly the same as passing the whole image only once through this new CNN. ",
              "instructor_notes": ""
            },
            {
              "id": 626648,
              "key": "895dc99e-6932-4711-821e-d819d8a063b1",
              "title": null,
              "semantic_type": "ImageAtom",
              "is_public": true,
              "url": "https://video.udacity-data.com/topher/2018/May/5af331d6_last/last.png",
              "non_google_url": "https://s3.cn-north-1.amazonaws.com.cn/u-img/895dc99e-6932-4711-821e-d819d8a063b1",
              "caption": "",
              "alt": "",
              "width": 1280,
              "height": 720,
              "instructor_notes": null
            },
            {
              "id": 624530,
              "key": "afd36305-a2d8-46e2-b2ba-b6506ffe16cf",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "This is how you can apply sliding windows with a CNN.  This technique makes the whole process much more efficient. However, this technique has a downside: the position of the bounding boxes is not going to be very accurate. The reason is that it is quite unlikely that a given size window and stride will be able to match the objects in the images perfectly. In order to increase the accuracy of the bounding boxes, YOLO uses a grid instead of sliding windows, in addition to two other techniques, known as Intersection Over Union and Non-Maximal Suppression.\n\nThe combination of the above techniques is part of the reason the YOLO algorithm works so well. Before diving into how YOLO puts all these techniques together, we will look first at each technique individually.\n",
              "instructor_notes": ""
            }
          ]
        },
        {
          "id": 621546,
          "key": "52d1a56c-7ca1-49bb-82d3-6c62fed80721",
          "title": "Using a Grid",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "52d1a56c-7ca1-49bb-82d3-6c62fed80721",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 626101,
              "key": "54f7744b-05d9-477c-b262-6eb8f461f116",
              "title": "04 Using A Grid To Improve Localization V2",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "OmgR35Go79Y",
                "china_cdn_id": "OmgR35Go79Y.mp4"
              }
            }
          ]
        },
        {
          "id": 621547,
          "key": "2b5c2922-5c0e-437c-9c95-4ebaccdeea81",
          "title": "Training on a Grid",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "2b5c2922-5c0e-437c-9c95-4ebaccdeea81",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 626102,
              "key": "1b17510b-c192-4690-9b74-00ae09e193fa",
              "title": "05 Training On A Grid V2",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "uhefpakvXh8",
                "china_cdn_id": "uhefpakvXh8.mp4"
              }
            }
          ]
        },
        {
          "id": 621548,
          "key": "be2bd17c-cb5e-4ec7-8266-e7fd9412f43c",
          "title": "Generating Bounding Boxes",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "be2bd17c-cb5e-4ec7-8266-e7fd9412f43c",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 626103,
              "key": "4ce223fa-2e03-4c5e-8257-c8c4e24aa804",
              "title": "06 Generating Bounding Boxes V3",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "TGfPX-XcyOs",
                "china_cdn_id": "TGfPX-XcyOs.mp4"
              }
            },
            {
              "id": 771262,
              "key": "2d6896fe-15b9-40e0-996f-51af6055d0be",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "视频52''，网格位置 应为g34\n\n视频53‘’，网格位置 应为g35",
              "instructor_notes": ""
            }
          ]
        },
        {
          "id": 621549,
          "key": "8290b2dc-1b41-4e58-a842-d0ac26b62458",
          "title": "Quiz: Generating Boxes and Detecting Objects",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "8290b2dc-1b41-4e58-a842-d0ac26b62458",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 621663,
              "key": "807cd3df-98b8-4855-a4e9-31f68351159c",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "### Seeing a Test Image \n\nWhat do you think will happen once a network, like the CNN we've been talking about, sees a new, test image with an object in it? First, our network has to break this new, test image into a grid.",
              "instructor_notes": ""
            },
            {
              "id": 621668,
              "key": "75149b20-757c-4d6a-b9bd-849bc1ffadda",
              "title": null,
              "semantic_type": "ImageAtom",
              "is_public": true,
              "url": "https://video.udacity-data.com/topher/2018/May/5aebb067_screen-shot-2018-05-03-at-5.58.54-pm/screen-shot-2018-05-03-at-5.58.54-pm.png",
              "non_google_url": "https://s3.cn-north-1.amazonaws.com.cn/u-img/75149b20-757c-4d6a-b9bd-849bc1ffadda",
              "caption": "An image of a woman working broken into a grid of cells; 5 of which are labelled: A, B, C, D, and E.",
              "alt": "",
              "width": 500,
              "height": 416,
              "instructor_notes": null
            },
            {
              "id": 621665,
              "key": "806865cd-4083-472e-a8c1-1d1177fde40d",
              "title": "",
              "semantic_type": "CheckboxQuizAtom",
              "is_public": true,
              "instructor_notes": null,
              "user_state": {
                "node_key": "806865cd-4083-472e-a8c1-1d1177fde40d",
                "completed_at": null,
                "last_viewed_at": null,
                "unstructured": null
              },
              "question": {
                "prompt": "For the above image, which cell do you think will predict the bounding box for the person in that image? (You may select multiple cells if you think more than one will detect the person and produce a bounding box.)",
                "answers": [
                  {
                    "id": "a1525394924340",
                    "text": "A",
                    "is_correct": true
                  },
                  {
                    "id": "a1525394985192",
                    "text": "B",
                    "is_correct": false
                  },
                  {
                    "id": "a1525394987110",
                    "text": "C",
                    "is_correct": false
                  },
                  {
                    "id": "a1525394988643",
                    "text": "D",
                    "is_correct": false
                  },
                  {
                    "id": "a1525395550990",
                    "text": "E",
                    "is_correct": false
                  }
                ]
              }
            }
          ]
        },
        {
          "id": 621669,
          "key": "f8ad9350-f246-4285-b2db-90adc1c8aea7",
          "title": "Too Many Boxes",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "f8ad9350-f246-4285-b2db-90adc1c8aea7",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 626104,
              "key": "cf8955b7-acb1-4ea2-b785-85ff4a74e243",
              "title": "07 Too Many Boxes V2",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "nYDWsFdFnQ8",
                "china_cdn_id": "nYDWsFdFnQ8.mp4"
              }
            }
          ]
        },
        {
          "id": 621550,
          "key": "8b63817b-391a-4586-bb27-04d892de92a6",
          "title": "Intersection over Union (IoU)",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "8b63817b-391a-4586-bb27-04d892de92a6",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 626105,
              "key": "5482c4aa-5468-4fd7-b0cd-348e2136dc57",
              "title": "08 Intersection Over Union IOU V1",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "ieKEHlEjIsY",
                "china_cdn_id": "ieKEHlEjIsY.mp4"
              }
            }
          ]
        },
        {
          "id": 621551,
          "key": "7720d195-3990-4ecf-b851-36a0620e631d",
          "title": "Quiz: IoU and Overlap Limits",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "7720d195-3990-4ecf-b851-36a0620e631d",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 621672,
              "key": "73186b22-b361-4352-bcfa-4242901827f7",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "### Intersection over Union (IoU)\n\nWe know the IoU is given by the area of: intersection/union. The next couple questions will test your intuition about what values IoU can take as it compares two bounding boxes.",
              "instructor_notes": ""
            },
            {
              "id": 621674,
              "key": "21dfb6ba-6c18-4c68-af74-29cd8a8f0282",
              "title": null,
              "semantic_type": "ImageAtom",
              "is_public": true,
              "url": "https://video.udacity-data.com/topher/2018/May/5aebb259_screen-shot-2018-05-03-at-6.07.12-pm/screen-shot-2018-05-03-at-6.07.12-pm.png",
              "non_google_url": "https://s3.cn-north-1.amazonaws.com.cn/u-img/21dfb6ba-6c18-4c68-af74-29cd8a8f0282",
              "caption": "Two bounding boxes. Intersection in dark green and union in light green.",
              "alt": "",
              "width": 400,
              "height": 592,
              "instructor_notes": null
            },
            {
              "id": 621673,
              "key": "58f1484f-5d7a-4946-88f4-104894aa8585",
              "title": "",
              "semantic_type": "RadioQuizAtom",
              "is_public": true,
              "instructor_notes": null,
              "user_state": {
                "node_key": "58f1484f-5d7a-4946-88f4-104894aa8585",
                "completed_at": null,
                "last_viewed_at": null,
                "unstructured": null
              },
              "question": {
                "prompt": "Imagine you’re comparing a ground truth box to a predicted box. If you want your predicted box to be as close to this ground truth box as possible, what would you want the IoU to be?",
                "answers": [
                  {
                    "id": "a1525395809101",
                    "text": "0",
                    "is_correct": false
                  },
                  {
                    "id": "a1525395840016",
                    "text": "0.5",
                    "is_correct": false
                  },
                  {
                    "id": "a1525395842564",
                    "text": "1",
                    "is_correct": true
                  },
                  {
                    "id": "a1525395844984",
                    "text": "2",
                    "is_correct": false
                  }
                ]
              }
            },
            {
              "id": 621675,
              "key": "ca412f85-69f2-4e4a-a7ad-083f59cce3f1",
              "title": "",
              "semantic_type": "RadioQuizAtom",
              "is_public": true,
              "instructor_notes": null,
              "user_state": {
                "node_key": "ca412f85-69f2-4e4a-a7ad-083f59cce3f1",
                "completed_at": null,
                "last_viewed_at": null,
                "unstructured": null
              },
              "question": {
                "prompt": "What is the lowest value IoU can have?",
                "answers": [
                  {
                    "id": "a1525396098634",
                    "text": "-2",
                    "is_correct": false
                  },
                  {
                    "id": "a1525396111031",
                    "text": "-1",
                    "is_correct": false
                  },
                  {
                    "id": "a1525396112928",
                    "text": "0",
                    "is_correct": true
                  },
                  {
                    "id": "a1525396115030",
                    "text": "0.5",
                    "is_correct": false
                  }
                ]
              }
            },
            {
              "id": 621676,
              "key": "fb6b867f-15cd-43d7-b4c9-0300b9598c45",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "### IoU Values\n\nThe IoU between two bounding boxes will always have a value between 0 and 1 because, as two boxes drift apart, their intersection approaches 0, but if two bounding boxes overlap *perfectly* their IoU will be 1.\nSo, the higher the IOU the more overlap there is between the two bounding boxes!\n\nIn the next video we will see how Non-Maximal suppression uses the IOU to only choose the best bounding box.\n",
              "instructor_notes": ""
            },
            {
              "id": 621677,
              "key": "1bdb9f67-8b7b-4383-90fc-1cf9608b474c",
              "title": null,
              "semantic_type": "ImageAtom",
              "is_public": true,
              "url": "https://video.udacity-data.com/topher/2018/May/5aebb315_screen-shot-2018-05-03-at-6.10.29-pm/screen-shot-2018-05-03-at-6.10.29-pm.png",
              "non_google_url": "https://s3.cn-north-1.amazonaws.com.cn/u-img/1bdb9f67-8b7b-4383-90fc-1cf9608b474c",
              "caption": "Examples of maximum and minimum IoU values between two boxes.",
              "alt": "",
              "width": 400,
              "height": 490,
              "instructor_notes": null
            }
          ]
        },
        {
          "id": 621552,
          "key": "70c523ad-238b-46af-bc27-ad4b186c4617",
          "title": "Non-Maximal Suppression",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "70c523ad-238b-46af-bc27-ad4b186c4617",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 626106,
              "key": "65a304c7-c2b2-420d-a776-581f28daa125",
              "title": "09 NonMaximal Suppression V1",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "TE6M29Jo9hk",
                "china_cdn_id": "TE6M29Jo9hk.mp4"
              }
            },
            {
              "id": 621679,
              "key": "bfcdf98a-4153-4e2f-9446-87a0273e715d",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "### Non-Maximal Suppression Steps\n\nIn practice Non-maximal Suppression is implemented in a few steps.\n\n1. Look at the output vector of each grid cell. Recall that each grid cell will have an output vector with a  Pc value and bounding box coordinates.\n2. Remove all bounding boxes that have a Pc value less than or equal to some threshold, say 0.5. Therefore, we will only keep a bounding box, if there is more than a 50% chance of an object being inside of it. \n3. Select the bounding box with the highest Pc value.\n4. Remove all the bounding boxes that have a high IoU* with the box selected in the last step.\n\n\\* A high IoU usually means a that the IoU is greater than or equal to 0.5.",
              "instructor_notes": ""
            }
          ]
        },
        {
          "id": 621553,
          "key": "a01f45f8-9cae-4537-932f-ab51e56c0182",
          "title": "Anchor Boxes",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "a01f45f8-9cae-4537-932f-ab51e56c0182",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 626282,
              "key": "fb9fe994-53d6-4481-a622-8b58640a215b",
              "title": "10 Anchor Boxes V3",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "IzILYgVb76g",
                "china_cdn_id": "IzILYgVb76g.mp4"
              }
            },
            {
              "id": 621681,
              "key": "37dd3ef4-1367-4520-a496-eaac2fb47637",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "### Anchor Boxes and Vehicle Detection\n\nIf you liked learning about anchor boxes, check out [this blog post](https://medium.com/@vivek.yadav/part-1-generating-anchor-boxes-for-yolo-like-network-for-vehicle-detection-using-kitti-dataset-b2fe033e5807) about using anchor boxes and YOLO for vehicle detection!",
              "instructor_notes": ""
            }
          ]
        },
        {
          "id": 621554,
          "key": "60d9cdf8-161d-4755-80e4-a167441e39d9",
          "title": "YOLO Algorithm",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "60d9cdf8-161d-4755-80e4-a167441e39d9",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 626283,
              "key": "6d23cdf0-da79-47eb-ad75-d422678dee7b",
              "title": "11 YOLO Algorithm V3",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "ZbQzCHQ8YEo",
                "china_cdn_id": "ZbQzCHQ8YEo.mp4"
              }
            },
            {
              "id": 626589,
              "key": "995f343d-9079-41a1-afb1-cbf079b75566",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "### Exercise repository\n\nNote that the next code example, will not be available in the public [exercise repo](https://github.com/udacity/CVND_Exercises) due to the model weights being too large a file. As such, the following YOLO implementation is available only in Workspaces. But, you will find most of the notebooks in this module available for download, there!",
              "instructor_notes": ""
            }
          ]
        },
        {
          "id": 626978,
          "key": "4d652897-bfd0-429a-a3b7-5ed24832317d",
          "title": "Notebook: YOLO Implementation",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "4d652897-bfd0-429a-a3b7-5ed24832317d",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 626985,
              "key": "4844fd42-a0ff-4e0b-bdc3-1b6163884ba8",
              "title": null,
              "semantic_type": "WorkspaceAtom",
              "is_public": true,
              "workspace_id": "view1354ef39",
              "pool_id": "jupyter",
              "view_id": "1354ef39-cebe-4cd7-a0c2-e220e7aec546",
              "gpu_capable": false,
              "configuration": {
                "id": "reserved",
                "blueprint": {
                  "conf": {
                    "disk": null,
                    "ports": [],
                    "allowSubmit": false,
                    "defaultPath": "/notebooks/YOLO.ipynb"
                  },
                  "kind": "jupyter"
                },
                "workspaceId": "reserved"
              },
              "starter_files": null
            }
          ]
        }
      ]
    }
  },
  "_deprecated": [
    {
      "name": "non_google_url",
      "reason": "(2016/8/18) Not sure, ask i18n team for reason"
    },
    {
      "name": "non_google_url",
      "reason": "(2016/8/18) Not sure, ask i18n team for reason"
    },
    {
      "name": "non_google_url",
      "reason": "(2016/8/18) Not sure, ask i18n team for reason"
    },
    {
      "name": "non_google_url",
      "reason": "(2016/8/18) Not sure, ask i18n team for reason"
    },
    {
      "name": "non_google_url",
      "reason": "(2016/8/18) Not sure, ask i18n team for reason"
    },
    {
      "name": "non_google_url",
      "reason": "(2016/8/18) Not sure, ask i18n team for reason"
    },
    {
      "name": "non_google_url",
      "reason": "(2016/8/18) Not sure, ask i18n team for reason"
    },
    {
      "name": "non_google_url",
      "reason": "(2016/8/18) Not sure, ask i18n team for reason"
    },
    {
      "name": "non_google_url",
      "reason": "(2016/8/18) Not sure, ask i18n team for reason"
    },
    {
      "name": "non_google_url",
      "reason": "(2016/8/18) Not sure, ask i18n team for reason"
    },
    {
      "name": "non_google_url",
      "reason": "(2016/8/18) Not sure, ask i18n team for reason"
    },
    {
      "name": "non_google_url",
      "reason": "(2016/8/18) Not sure, ask i18n team for reason"
    }
  ]
}