WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:03.270
当我们提到图像定位时

00:00:03.270 --> 00:00:05.924
讨论了如何创建一个 CNN

00:00:05.924 --> 00:00:11.740
该 CNN 能够输出图像中对象的预测类别并为该对象输出预测的边界框

00:00:11.740 --> 00:00:14.394
在我们见过的 CNN 示例中

00:00:14.394 --> 00:00:18.164
这些输出是单独分析的

00:00:18.164 --> 00:00:22.774
并使用分类和回归损失的组合权重训练网络

00:00:22.774 --> 00:00:28.190
另一种处理这些输出的方式是将它们合并成一个输出向量

00:00:28.190 --> 00:00:30.304
这正是 YOLO 算法采用的方式

00:00:30.304 --> 00:00:32.409
我们来看一个示例

00:00:32.409 --> 00:00:36.899
假设我要训练一个 CNN 来识别三种类别

00:00:36.899 --> 00:00:38.969
人 猫和狗

00:00:38.969 --> 00:00:41.659
在此示例中 因为只有三个类别

00:00:41.659 --> 00:00:44.789
因此输出向量 y 将只有三个元素

00:00:44.789 --> 00:00:47.009
c1 c2 c3

00:00:47.009 --> 00:00:49.280
每个元素都是一个类别得分

00:00:49.280 --> 00:00:52.564
或图像是人 猫或狗的概率

00:00:52.564 --> 00:00:54.079
如果有更多类别

00:00:54.079 --> 00:00:55.954
这个向量将变得更长

00:00:55.954 --> 00:00:59.489
对于这个图像 我们希望训练 CNN 识别图像中的人

00:00:59.490 --> 00:01:03.740
并用一个边界框定位此人

00:01:03.740 --> 00:01:07.609
为此 我们可以向输出向量中添加一些方框参数

00:01:07.609 --> 00:01:09.715
我们可以添加四个数字

00:01:09.715 --> 00:01:11.200
x y w 和 h

00:01:11.200 --> 00:01:15.439
用于确定边界框的位置和大小

00:01:15.439 --> 00:01:19.399
X 和 y 确定方框中心的坐标

00:01:19.400 --> 00:01:22.615
w 和 h 确定方框的宽和高

00:01:22.614 --> 00:01:28.409
一旦训练 CNN 输出类别概率和边界框坐标后

00:01:28.409 --> 00:01:32.804
离检测任何给定图像中的对象又近了一步

00:01:32.805 --> 00:01:35.970
接下来 我们将简单介绍你之前见过的滑动窗口方法

00:01:35.969 --> 00:01:38.969
并且考虑到我们的示例输出向量

00:01:38.969 --> 00:01:42.075
然后你将了解 YOLO 如何改善滑动窗口

00:01:42.075 --> 00:01:46.540
并将图像划分为网格 以便高效地检测对象

