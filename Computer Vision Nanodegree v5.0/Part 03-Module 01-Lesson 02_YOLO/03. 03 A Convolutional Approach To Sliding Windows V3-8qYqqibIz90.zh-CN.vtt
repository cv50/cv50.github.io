WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:03.539
因为对象可以在给定图像的任何位置

00:00:03.539 --> 00:00:07.349
你可以通过在整个图像上滑动一个小窗口

00:00:07.349 --> 00:00:11.894
并检查创建的每个窗口中是否有对象 确保检测到所有这些对象

00:00:11.894 --> 00:00:14.009
这是滑动窗口方法

00:00:14.009 --> 00:00:16.140
我们详细了解下该方法的原理

00:00:16.140 --> 00:00:19.859
假设我已经训练 CNN 识别三个类别

00:00:19.859 --> 00:00:21.939
人 猫和狗

00:00:21.940 --> 00:00:25.725
现在我想使用这个训练的 CNN 检测图像中的人

00:00:25.725 --> 00:00:29.700
滑动窗口的第一步是选择窗口大小

00:00:29.699 --> 00:00:33.585
我们希望窗口足够小 能够捕获图像中的任何小对象

00:00:33.585 --> 00:00:36.679
然后将窗口放在图像的开始位置

00:00:36.679 --> 00:00:39.850
并将窗口中的区域馈送到训练的 CNN 中

00:00:39.850 --> 00:00:42.975
对于每个区域 这个 CNN 都会输出一个预测

00:00:42.975 --> 00:00:44.829
即这个输出向量 y

00:00:44.829 --> 00:00:47.554
注意这个向量中的第一个元素 pc

00:00:47.554 --> 00:00:50.299
与我们之前看到的不一样

00:00:50.299 --> 00:00:53.719
pc 是介于 0 和 1 之间的概率

00:00:53.719 --> 00:00:56.789
表示窗口中是否有对象

00:00:56.789 --> 00:00:58.769
如果没有检测到对象

00:00:58.770 --> 00:01:03.240
我们就不需要继续尝试分类该图像区域

00:01:03.240 --> 00:01:06.185
向量中的其他值和之前的一样

00:01:06.185 --> 00:01:08.060
有 c1 c2 和 c3

00:01:08.060 --> 00:01:12.879
对应的是检测到的对象类别 然后是边界框坐标

00:01:12.879 --> 00:01:15.604
在此示例中 我们发现第一个窗口区域

00:01:15.605 --> 00:01:18.245
不包含我们要查找的任何类别

00:01:18.245 --> 00:01:20.740
没有人 猫和狗

00:01:20.739 --> 00:01:24.919
此时 CNN 将输出一个 pc 等于 0 的向量

00:01:24.920 --> 00:01:27.820
因为在窗口内没有检测到任何对象

00:01:27.819 --> 00:01:30.769
然后继续移动 使用某个很小的步长

00:01:30.769 --> 00:01:33.754
将窗口滑动到右侧并继续这一流程

00:01:33.754 --> 00:01:37.399
小的步长可以确保捕获任何对象

00:01:37.400 --> 00:01:41.865
并使对象的位置与真实位置只相差几个像素

00:01:41.864 --> 00:01:45.314
因为这个区域也不包含任何对象

00:01:45.314 --> 00:01:48.379
因此再次返回 pc 等于 0

00:01:48.379 --> 00:01:52.299
重复这一流程 直到覆盖整个图像

00:01:52.299 --> 00:01:56.689
你还可以使用不同大小的窗口重新分析整个图像

00:01:56.689 --> 00:02:00.259
其中一个检测窗口可能会准确地在图像中检测到一个小的对象

00:02:00.260 --> 00:02:04.140
另一个窗口可能会更好地捕获大的对象

00:02:04.140 --> 00:02:09.300
现在可以看出 当我们将这个窗口中的区域馈送到 CNN 中后

00:02:09.300 --> 00:02:12.260
CNN 生成了一个 pc 等于 1 的 y 向量

00:02:12.259 --> 00:02:17.909
表示发现了一个对象 并且将 c1 设为 1

00:02:17.909 --> 00:02:19.799
表示此对象是人

00:02:19.800 --> 00:02:23.250
在现实中 这些概率值通常会非常接近 1

00:02:23.250 --> 00:02:27.120
但是不完全等于 1 因为存在某些不确定性

00:02:27.120 --> 00:02:29.759
我们的模型还提供了预测边界框坐标

00:02:29.759 --> 00:02:33.129
这些坐标由窗口确定

00:02:33.129 --> 00:02:35.849
滑动窗口方法效果不错

00:02:35.849 --> 00:02:39.644
但是非常消耗计算资源

00:02:39.645 --> 00:02:41.610
因为我们需要用不同大小的窗口扫描整个图像

00:02:41.610 --> 00:02:45.490
并且需要将每个窗口馈送到 CNN 中

00:02:45.490 --> 00:02:50.170
你已经见过一种解决方法 即将输入图像中的感兴趣区域

00:02:50.169 --> 00:02:55.049
投射到 CNN 中的更深层级 也就是投射到一组特征图中

00:02:55.050 --> 00:02:59.650
这样的话 只需将图像传入多个卷积和池化层一次

00:02:59.650 --> 00:03:04.659
并使用生成的特征图分析输入图像的不同区域

00:03:04.659 --> 00:03:06.704
但是 YOLO 采用不同的方法

00:03:06.705 --> 00:03:11.905
它也是只查看图像的每个部分一次 并且不会重叠窗口

00:03:11.905 --> 00:03:15.370
你认为应该如何划分整个图像

00:03:15.370 --> 00:03:19.730
才能在分析图像时不用查看一个区域多次？

