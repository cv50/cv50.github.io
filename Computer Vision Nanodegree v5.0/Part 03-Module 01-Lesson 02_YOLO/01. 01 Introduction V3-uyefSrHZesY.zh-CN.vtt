WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:06.615
你已经学习了

00:00:06.615 --> 00:00:08.400
多种用于识别和定位场景中

00:00:08.400 --> 00:00:11.445
多个对象的区域方法

00:00:11.445 --> 00:00:14.410
Faster R-CNN 等架构比较准确

00:00:14.410 --> 00:00:16.629
但是模型本身很复杂

00:00:16.629 --> 00:00:20.355
有多个输出 每个都有可能存在错误

00:00:20.355 --> 00:00:23.935
训练过后 速度依然不够快 无法实时运行

00:00:23.934 --> 00:00:28.169
在这节课 我们将学习 YOLO 它是 You Only Look Once 的简称

00:00:28.170 --> 00:00:30.840
是一种实时对象检测算法

00:00:30.839 --> 00:00:34.500
避免了花费大量时间生成候选区域

00:00:34.500 --> 00:00:36.564
它的优先级是速度和识别能力

00:00:36.564 --> 00:00:39.429
而不是完美地定位对象

00:00:39.429 --> 00:00:42.240
我们来看一个实际 YOLO 示例

00:00:42.240 --> 00:00:45.800
假设无人驾驶汽车看到这个街道图像

00:00:45.799 --> 00:00:48.379
无人驾驶汽车必须能够

00:00:48.380 --> 00:00:50.980
检测周围所有对象的位置

00:00:50.979 --> 00:00:53.674
例如行人 汽车和交通信号灯

00:00:53.674 --> 00:00:57.259
除此之外 这种检测必须几乎实时发生

00:00:57.259 --> 00:01:00.155
使汽车能够安全地行驶在街道上

00:01:00.155 --> 00:01:03.560
汽车不需要始终知道所有这些对象是什么

00:01:03.560 --> 00:01:07.594
主要需要知道不要撞到它们

00:01:07.594 --> 00:01:09.739
但是需要识别交通信号灯 自行车和行人

00:01:09.739 --> 00:01:12.464
以便正确地遵守交通规则

00:01:12.465 --> 00:01:18.020
在这个图像中 我们使用 YOLO 算法定位并分类了不同的对象

00:01:18.019 --> 00:01:23.009
每个对象周围都有一个边界框和相应的分类标签

00:01:23.010 --> 00:01:28.400
在下面的几个视频中 我们将详细了解 YOLO 算法的原理

